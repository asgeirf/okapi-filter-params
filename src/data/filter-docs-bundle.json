{"generatedAt":"2026-02-18T13:54:43Z","filters":{"okf_archive":{"filterName":"Archive Filter","overview":"The Archive Filter allows you to process different types of files stored in a ZIP archive file (e.g. .zip or .jar files). It extracts files matching specified name patterns from the archive and processes them using designated Okapi filter configurations.","parameters":{"mimeType":{"description":"The MIME type for the format of the archive file. This identifies the container format being processed (e.g. ZIP, JAR)."},"fileNames":{"description":"One or more file names to match against entries inside the archive. If several file names are listed they must be comma-delimited. Standard file wildcards (? and *) are supported. Files matching these patterns in any directory inside the ZIP file will be extracted for processing. There must be exactly as many file names as filter configuration identifiers in the configIds field, and they must be in the same order.","dependsOn":[{"property":"configIds","condition":"must have the same number of entries and be in the same order"}]},"configIds":{"description":"One or more Okapi filter configuration identifiers, comma-delimited. Each configuration id corresponds positionally to a file name pattern in the fileNames field. For example, 'okf_properties' would process matched files using the Properties Filter with its default configuration. There must be exactly as many configuration ids as there are file names.","dependsOn":[{"property":"fileNames","condition":"must have the same number of entries and be in the same order"}]},"moveLeadingAndTrailingCodesToSkeleton":{"description":"When enabled, inline codes that appear at the beginning or end of a segment are moved to the skeleton (non-translatable) portion, keeping them out of the translatable text."},"mergeAdjacentCodes":{"description":"When enabled, consecutive inline codes are merged into a single placeholder, simplifying the inline code representation for translators."},"simplifierRules":{"description":"Rules for simplifying inline code representation. These rules control how complex inline codes are reduced to simpler placeholders for translation."}},"processingNotes":["The filter takes an archive document (e.g. a ZIP file) as input and extracts any files matching the specified name or pattern, processing each with the filter identified by the corresponding filter configuration id.","Files matching the name patterns are found in any directory inside the ZIP file, not just the root level."],"limitations":["None known."],"examples":[{"title":"Processing properties files inside a ZIP archive","description":"Extract and process all files named Res.properties from any directory inside a ZIP file using the Properties Filter with its default configuration.","input":"File names: Res.properties\nFilter configuration ids: okf_properties","output":"All files named Res.properties (in any directory inside the ZIP file) will be extracted using the Properties Filter with its default configuration."}],"filterId":"okf_archive","wikiUrl":"https://okapiframework.org/wiki/index.php/archive_filter"},"okf_doxygen":{"filterName":"Doxygen Filter","overview":"The Doxygen Filter is an Okapi component for extracting Doxygen-style comments from source code files. It supports C++-style (///), Javadoc-style (/**), Qt-style (/*!), and Python-style (''' or \"\"\") comment blocks. The full set of Doxygen special commands, HTML commands, and XML commands are recognized and interpreted, with translatable text extracted as Text Units while commands are represented as inline codes.","parameters":{"preserve_whitespace":{"description":"Controls whether the filter collapses whitespace in extracted text. When set to false (the default), the filter collapses whitespace in text runs. Set to true to prevent the filter from collapsing whitespace.","notes":["When false, single linebreaks in a text run that are not part of a Doxygen command are collapsed, and each translatable paragraph will be collapsed to a single (potentially very long) line."]},"doxygen_commands":{"description":"A map of supported Doxygen commands and their extraction behavior. Each entry is keyed by the command name (as it appears in the Doxygen comment, without prefix/suffix, case-sensitive) and defines the command's type, inline status, pairing, translatability, and parameters. Commands have a 'type' of PLACEHOLDER, OPENING, or CLOSING. OPENING/CLOSING commands must specify a 'pair' identifying the matched command (e.g. 'code' pairs with 'endcode'). The optional 'inline' flag (default false) controls whether the command is treated as inline or block-level. The optional 'translatable' flag (default true) controls whether the entire content delimited by a block-level OPENING command is translatable (e.g. \\code sets translatable: false). Each command may have an ordered list of 'parameters', each with a 'name' (organizational only), 'length' (WORD, LINE, PHRASE, or PARAGRAPH), 'required' flag (default true), and 'translatable' flag (default true). WORD matches a single whitespace-delimited token; LINE matches to end of line; PHRASE matches a double-quoted string like '\"image caption\"'; PARAGRAPH matches to the next blank line or command. Untranslatable parameters following translatable ones are recorded as separate inline codes.","notes":["The 'parameters' listing is optional for each command.","When present, parameters should be listed in the order in which they are written following the command.","Parameters with non-whitespace delimiters (e.g. '.py' in \\code{.py}) are not currently supported."]},"html_commands":{"description":"A map of recognized HTML and XML commands within Doxygen comments and their extraction behavior. Each entry is keyed by the HTML/XML tag name (e.g. 'a', 'b', 'strong', 'summary') and follows the same structure as doxygen_commands entries, with 'type' (OPENING or PLACEHOLDER) and optional 'inline' flag. These cover standard HTML tags supported by Doxygen (a, b, blockquote, body, br, center, code, div, dl, em, h1-h3, i, li, ol, p, pre, small, span, strong, sub, sup, table, td, th, tr, tt, ul, etc.) as well as XML documentation tags (c, description, example, exception, include, inheritdoc, item, list, para, param, paramref, permission, remarks, returns, see, seealso, summary, term, typeparam, typeparamref, value)."},"path":{"description":"The file path for the filter configuration. Used internally to reference the configuration file location."},"simplifierRules":{"description":"Rules for simplifying inline code representation in the extracted text. Allows customizing how inline codes (placeholders, tags, etc.) are detected and handled during extraction."}},"limitations":["Single linebreaks in a text run that are not part of a Doxygen command are collapsed. No effort is made to enforce a maximum line width upon output, so each translatable paragraph will be collapsed to a single (potentially very long) line.","Command parameters with non-whitespace delimiters (e.g. '.py' in \\code{.py}) are not currently supported.","Non-translatable command parameters are not exposed for any special processing."],"processingNotes":["If the file has a Unicode Byte-Order-Mark, the corresponding encoding (e.g. UTF-8, UTF-16) is used. Otherwise, the input encoding is the default encoding specified when opening the document.","The full set of Doxygen special commands, HTML commands, and XML commands are recognized and interpreted as inline codes in the extracted Text Units.","The filter preserves line numbers so that a one-to-one correspondence between source line number and translated line number is maintained.","C++-style (///), Javadoc-style (/**), Qt-style (/*!), and Python-style (''' or \"\"\") comment blocks are supported."],"examples":[{"title":"Basic Doxygen comment extraction","description":"Shows how a Doxygen comment block with \\class and \\brief commands is extracted into Text Units, with commands converted to inline codes.","input":"/*! \\class Test class.h \"inc/class.h\"\n *  \\brief This is a test class.\n *\n * Some details about the Test class\n */","output":"Text Unit 1: <1/><2/> This is a test class.\nText Unit 2: Some details about the Test class"},{"title":"Inline and block comment styles","description":"Demonstrates the various Doxygen comment styles supported by the filter, including Qt-style (/*!), Javadoc-style (/**), member-after (//!< and /**<), and how translatable text is extracted from each.","input":"/*! A test class */\nclass Test\n{\n  public:\n    /** An enum type.\n     * The documentation block cannot be put after the enum!\n     */\n    enum EnumType\n    {\n      int EVal1, /**< enum value 1 */\n      int EVal2 /**< enum value 2 */\n    };\n    void member(); //!< a member function.\n  protected:\n    int value; /*!< an integer value */\n};","output":"Translatable strings extracted: 'A test class', 'An enum type.', 'The documentation block cannot be put after the enum!', 'enum value 1', 'enum value 2', 'a member function.', 'an integer value'"},{"title":"Custom command definition","description":"Shows how to define a custom command using a regex pattern in the custom_commands section of the configuration. Matches are turned into codes according to the standard parameter options.","input":"custom_commands:\n  - pattern: \"###ACCESS_CHECKS###.*?;\"\n    type: PLACEHOLDER","output":"Text matching the regex pattern will be converted to PLACEHOLDER inline codes during extraction."},{"title":"Doxygen command configuration entry","description":"Shows the YAML structure for defining a doxygen_commands entry with type, inline flag, pair, translatability, and ordered parameters.","input":"doxygen_commands:\n  code:\n    type: OPENING\n    inline: false\n    pair: endcode\n    translatable: false\n    parameters: []","output":"Content between \\code and \\endcode will be treated as a non-translatable block."}],"filterId":"okf_doxygen","wikiUrl":"https://okapiframework.org/wiki/index.php/doxygen_filter"},"okf_dtd":{"filterName":"DTD Filter","overview":"This filter processes DTD (Document Type Definition) documents, specifically XML-DTDs that contain translatable text entity declarations. A common use case is Mozilla DTD files that accompany XUL documents used to build user-interface components. The filter extracts translatable text from ENTITY declarations and supports inline code detection via regular expressions.","parameters":{"useCodeFinder":{"description":"Enables or disables pattern-based detection of inline codes within extracted text. When set to true, the regular expressions defined in codeFinderRules are applied to identify spans of text that should be treated as inline codes (e.g., variables like VAR1 that need to be protected from modification). Works in conjunction with codeFinderRules to define what patterns are recognized as codes.","notes":["When using YAML notation for the configuration file, backslashes in regular expressions must be double-escaped (e.g., \\\\bVAR\\\\d\\\\b for the regex \\bVAR\\d\\b)."]},"moveLeadingAndTrailingCodesToSkeleton":{"description":"When enabled, inline codes that appear at the beginning or end of a segment are moved out of the translatable content and into the skeleton (non-translatable framework). This can simplify translation by removing codes that translators do not need to reposition.","dependsOn":[{"property":"useCodeFinder","condition":"must be true for inline codes to be detected in the first place"}]},"mergeAdjacentCodes":{"description":"When enabled, consecutive inline codes that appear next to each other are merged into a single placeholder code. This simplifies the translatable content by reducing the number of individual code placeholders translators must handle.","dependsOn":[{"property":"useCodeFinder","condition":"must be true for inline codes to be detected in the first place"}]},"simplifierRules":{"description":"Rules for simplifying the inline code representation in extracted text. These rules define how complex inline code patterns can be reduced to simpler placeholder representations, making the content easier for translators to work with.","dependsOn":[{"property":"useCodeFinder","condition":"must be true for inline codes to be present for simplification"}]}},"processingNotes":["If the file has a Unicode Byte-Order-Mark (BOM), the corresponding encoding (e.g. UTF-8, UTF-16) is used automatically. Otherwise, the default encoding specified in the filter options is used.","For UTF-8 output: if the input was also UTF-8, a BOM is written only if one was detected in the input. If the input was not UTF-8, no BOM is written in the output.","The type of line-breaks in the output is preserved from the original input document.","This filter does not have a graphical editor for configuration; a text editor must be used to create or modify custom configurations."],"limitations":["None known."],"examples":[{"title":"DTD with text entity declarations","description":"Example of a typical DTD file with translatable text entity declarations (e.g., Mozilla DTD files). The translatable text is the string value within each ENTITY declaration.","input":"<!--Comments-->\n<!ENTITY findWindow.title \"Find Files\">\n<!ENTITY fileMenu.label \"File\">\n<!ENTITY editMenu.label \"Edit\">"},{"title":"Inline code detection with useCodeFinder","description":"Using useCodeFinder and codeFinderRules to protect variables (like VAR1) from modification by treating them as inline codes. Note that backslashes must be double-escaped in YAML notation.","input":"useCodeFinder: true\ncodeFinderRules: \"#v1\\ncount.i=1\\nrule0=\\\\bVAR\\\\d\\\\b\"\n\n<!ENTITY dialog.fileCount \"Number of files = VAR1\">","output":"The text \"VAR1\" within the entity value is identified and marked as an inline code placeholder, protecting it from modification during translation."}],"filterId":"okf_dtd","wikiUrl":"https://okapiframework.org/wiki/index.php/dtd_filter"},"okf_epub":{"filterName":"EPUB Filter","overview":"This filter allows you to process EPUB (Electronic Publication) documents. It handles the EPUB archive format (application/epub+zip) and delegates processing of internal files to appropriate sub-filters based on configurable file name patterns and filter configuration IDs.","parameters":{"mimeType":{"description":"The MIME type of the filter's container format. For EPUB files, this identifies the archive format being processed. The default value is 'application/x-archive'."},"fileNames":{"description":"A comma-delimited list of file names to be processed within the EPUB archive. Wildcards are allowed (e.g., '*.tmx', '*.xlf'). The file names must be listed in the same order as the corresponding configuration IDs in the 'configIds' parameter. Default value is '*.tmx,*.xlf,*.xlff'.","dependsOn":[{"property":"configIds","condition":"must have entries in the same order, with a 1:1 correspondence between file name patterns and configuration IDs"}]},"configIds":{"description":"A comma-delimited list of Okapi filter configuration IDs corresponding to the file name patterns specified in 'fileNames'. Each configuration ID identifies which sub-filter to use for processing matching files within the EPUB archive. Default value is 'okf_tmx,okf_xliff,okf_xliff'.","dependsOn":[{"property":"fileNames","condition":"must have entries in the same order, with a 1:1 correspondence between configuration IDs and file name patterns"}]},"moveLeadingAndTrailingCodesToSkeleton":{"description":"When enabled, inline codes that appear at the beginning or end of a segment are moved to the skeleton (non-translatable) portion. This can simplify the translatable content by removing codes that are not embedded within the text."},"mergeAdjacentCodes":{"description":"When enabled, consecutive inline codes that appear next to each other are merged into a single placeholder. This reduces the number of individual inline codes translators need to handle."},"simplifierRules":{"description":"Rules for simplifying the inline code representation in extracted content. These rules define how complex inline code patterns should be simplified for translation tools."}},"limitations":["None known."],"processingNotes":["If the file has a Unicode Byte-Order-Mark (BOM), the corresponding encoding (e.g. UTF-8, UTF-16) is used for input.","If no BOM is present, the default encoding specified in the filter options is used for input.","For UTF-8 output: if the input was also UTF-8, a BOM is written only if one was detected in the input. If the input was not UTF-8, no BOM is written in the output.","This filter does not have a GUI editor for creating or modifying configuration files; a text editor must be used for custom configurations."],"examples":[],"filterId":"okf_epub","wikiUrl":"https://okapiframework.org/wiki/index.php/epuu_filter"},"okf_html":{"filterName":"HTML/XHTML Filter","overview":"The HTML Filter is an Okapi component that implements the IFilter interface for HTML and XHTML documents. It extracts translatable text and localizable attributes from HTML/XHTML content, supporting both well-formed (XHTML) and non-well-formed HTML parsing modes. The filter uses a YAML-based rule configuration to define how elements and attributes are categorized (inline, text unit, group, excluded, etc.) and which attributes are translatable, writable-localizable, or read-only.","parameters":{"assumeWellformed":{"description":"When set to true, the filter assumes the input HTML is well-formed XML (i.e., XHTML) and uses a stricter XML-based parser. This is faster but will fail on non-conforming HTML that is not well-formed. When false (the default), the filter uses a more lenient HTML parser that can handle common syntax errors such as unquoted attributes and missing closing tags. The predefined 'okf_html-wellFormed' configuration sets this to true.","notes":["When using well-formed mode, any structural tags that map to groups must have both a start and end tag, otherwise the filter will return an error.","The well-formed configuration includes GROUP rules for structural elements (table, ul, ol, dl, etc.) that are not present in the non-well-formed configuration."]},"preserve_whitespace":{"description":"When set to true, whitespace is preserved globally across all extracted text. When false (the default), whitespace handling depends on per-element rules — elements with the PRESERVE_WHITESPACE rule type (such as <pre>) will still preserve whitespace regardless of this global setting."},"skipEncodingDeclaration":{"description":"When set to true, the filter skips processing of encoding declarations in the HTML document. When false (the default), the filter reads and respects encoding declarations found in the document."},"attributes":{"description":"Global attribute extraction rules that apply across multiple elements. This is a map of attribute names to their rule configuration. Each entry specifies how a particular attribute should be handled wherever it appears in the document. Attribute names must be in lowercase in the configuration, regardless of their casing in the document. Attributes with a namespace prefix should be declared with the prefix in single quotes (e.g., 'xml:lang'). Each attribute rule includes a 'ruleTypes' array with one of: ATTRIBUTE_TRANS (translatable), ATTRIBUTE_WRITABLE (writable/modifiable but not translatable), ATTRIBUTE_READONLY (extracted but not modifiable), or ATTRIBUTE_ID (segment identifier). Rules can be scoped using 'allElementsExcept' (apply to all elements except listed ones) or 'onlyTheseElements' (apply only to listed elements).","notes":["All attribute names must be in lowercase in the configuration file, regardless of their casing in the document.","Attributes with a prefix should be declared with the prefix and between single quotes (e.g., 'xml:lang')."]},"elements":{"description":"Element extraction rules that define how each HTML element is processed by the filter. This is a map of element names to their rule configuration. Each entry specifies the rule types, translatable attributes, writable localizable attributes, read-only localizable attributes, ID attributes, conditions, and element type for that element. Element names must be in lowercase. Rule types include: INLINE (inline element within a text run, e.g., <b>, <i>), GROUP (structural grouping element, e.g., <table>, <div>), EXCLUDE (prevents extraction of text until end tag), INCLUDE (overrides exclusions for child elements), TEXTUNIT (starts a complex text unit with surrounding tags as skeleton, e.g., <p>, <title>), PRESERVE_WHITESPACE (preserves whitespace as-is, e.g., <pre>), ATTRIBUTES_ONLY (only attributes are translatable/localizable, no PCDATA), SCRIPT (embedded scripting language), and SERVER (embedded server language tags like JSP, PHP). Translatable attributes can be specified as a simple list of attribute names or as conditional key-value pairs using the condition syntax [attribute, operator, value] where operators are EQUALS, NOT_EQUALS, or MATCHES (regex). Element names can use regex patterns (e.g., '.*' to match all elements) for broad rules with conditions. The 'elementType' field maps to XLIFF 1.2 type values (e.g., bold, italic, link, image, paragraph).","notes":["All element names must be in lowercase in the configuration file.","Regex patterns can be used as element names (e.g., '.*' with conditions) to create broad inclusion/exclusion rules.","The HTML5 'translate' attribute is supported: elements with translate='no' are excluded, and elements with translate='yes' are included.","ATTRIBUTES_ONLY with translatableAttributes implies the tag will be a TEXTUNIT with embedded skeleton.","When using well-formed mode (assumeWellformed=true), structural tags mapped to GROUP must have both start and end tags."]},"simplifierRules":{"description":"Rules for simplifying inline code representation in extracted text. These rules control how inline codes (tags within text runs) are represented in the extracted content."},"taggedConfig":{"description":"Tagged configuration object for advanced filter configuration storage."},"editorTitle":{"description":"Title displayed in the parameters editor UI. Defaults to 'Parameters Editor'."},"path":{"description":"Path to an external configuration file."}},"limitations":["The content of <style> and <script> elements is not extracted.","Tags from server-side scripts such as PHP, ASPX, JSP, etc. are not formally supported and will be treated as non-translatable."],"processingNotes":["If the document has an encoding declaration it is used; otherwise, the default encoding specified in the filter options is used.","If the output encoding is UTF-8 and the input was also UTF-8, a Byte-Order-Mark is used only if one was detected in the input. If the input encoding was not UTF-8, no BOM is used in output.","If the input file has no declared encoding, the filter tries to add an encoding declaration in output: a <meta> tag for HTML files or a <meta /> tag for XHTML files. This addition only occurs if there is a <head> element in the file.","The type of line-breaks in the output matches the original input.","Character and numeric entities are converted to Unicode. Entities defined in a DTD or schema are passed through without change.","The filter attempts to clean up common syntax errors such as unquoted attributes by default (can be disabled with cleanupHtml: false)."],"examples":[{"title":"Inline Code Finder for variables","description":"Using the code finder to protect variable placeholders (e.g., VAR1) from translation by marking them as inline codes.","input":"useCodeFinder: true\ncodeFinderRules: \"#v1\\ncount.i=1\\nrule0=\\\\bVAR\\\\d\\\\b\"\n\nHTML input: <p>Number of files = VAR1</p>","output":"The text 'VAR1' is marked as an inline code within the extracted text unit."},{"title":"Inline Code Finder alternate YAML syntax","description":"A more readable YAML block-literal syntax for code finder rules, avoiding double-escaping of backslashes.","input":"useCodeFinder: true\ncodeFinderRules: |-\n    #v1\n    count.i=1\n    rule0=\\bVAR\\d\\b"},{"title":"Conditional translatable attributes","description":"Defining translatable attributes with conditions on the <input> element. Attributes are only translatable when the type attribute does not match certain values.","input":"input:\n  ruleTypes: [INLINE]\n  translatableAttributes:\n    alt: [type, NOT_EQUALS, [file, hidden, image, password]]\n    value: [type, NOT_EQUALS, [file, hidden, image, password]]\n    accesskey: [type, NOT_EQUALS, [file, hidden, image, password]]\n    title: [type, NOT_EQUALS, [file, hidden, image, password]]"},{"title":"Simple translatable attributes list","description":"A simple list of translatable attributes for the <area> element where all listed attributes are always translatable.","input":"area:\n  ruleTypes: [ATTRIBUTES_ONLY]\n  translatableAttributes: [accesskey, area, alt]"},{"title":"Character entity reference escaping","description":"Using escapeCharacters to output specific extended characters as HTML character entity references instead of literal Unicode characters.","input":"escapeCharacters: \"© €µÆĄ\"\n\nHTML input: <p>© €µÆĄ</p>","output":"<p>&copy;&nbsp;&euro;&micro;&AElig;Ą</p>\n\nOnly Ą (U+0104) is not represented as an entity reference because there is no HTML character entity defined for it."},{"title":"Exclude by default configuration","description":"Changing the default behavior to exclude all elements, then selectively including only the <title> element for translation.","input":"exclude_by_default: true\nelements:\n  title:\n    ruleTypes: [TEXTUNIT]"},{"title":"Inline CDATA handling","description":"Treating CDATA sections as inline elements to avoid breaking the flow of text.","input":"inlineCdata: true\n\nHTML input: <p>Text with <![CDATA[inline]]> CDATA</p>","output":"The <![CDATA[ and ]]> markers are treated as inline opening and closing tags, keeping the text flow intact."},{"title":"Quote mode configuration","description":"Configuring how quote and apostrophe characters are escaped in output. Mode 3 escapes only double quotes.","input":"quoteModeDefined: true\nquoteMode: 3"}],"filterId":"okf_html","wikiUrl":"https://okapiframework.org/wiki/index.php/html_filter"},"okf_html5":{"filterName":"HTML5-ITS Filter","overview":"This filter processes HTML5 documents that may contain ITS 2.0 (Internationalization Tag Set) markup. Input documents are expected to be valid HTML5. The filter supports global and local ITS rules and most ITS 2.0 data categories, with default behavior based on ITS defaults for language information, id values, within-text elements, and translate attributes. Default behavior can be overridden via ITS markup in the input document or through a filter parameters file (which is itself an ITS document).","parameters":{"simplifierRules":{"description":"Rules for simplifying inline code representation within extracted text units. These rules control how inline elements and codes are detected and simplified during processing."},"path":{"description":"Path to the ITS rules file used as the filter parameters. The parameters file is an ITS document that can override the default ITS behavior for the HTML5 filter. By default, the filter processes HTML5 documents based on ITS defaults: the 'lang' attribute is used for Language Information, the 'id' attribute for Id Value, most phrasing content elements are treated as withinText='yes', and the 'translate' attribute follows HTML5-specific behavior (which differs from XML). A custom parameters file can override any of these defaults using ITS 2.0 global and local rules."}},"limitations":["This filter is BETA."],"processingNotes":["The filter decides which encoding to use for the input document using the detection mechanism defined by the HTML5 specification.","The output encoding is the same as the input encoding, except if defined otherwise by the calling tool.","The type of line-breaks of the output is the same as the one of the original input.","Escaping of quote and apostrophe characters can be configured via quoteModeDefined and quoteMode properties in the config file. Quote modes: UNESCAPED=0 (no escaping), ALL=1 (named entities for both), NUMERIC_SINGLE_QUOTES=2 (named for double, numeric for single), DOUBLE_QUOTES_ONLY=3 (escape double quotes only)."],"examples":[{"title":"Default ITS rules configuration","description":"The default parameters file (an ITS 2.0 document) configures standard HTML5 processing: script/style/del elements are non-translatable, common attributes (abbr, alt, prompt, standby, summary, title) are translatable, input values are translatable except for hidden inputs, bidirectional markup is mapped, id attributes provide id values, pre/textarea preserve whitespace, and domain is derived from dcterms.subject or keywords meta tags.","input":"<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<its:rules xmlns:its=\"http://www.w3.org/2005/11/its\" version=\"2.0\"\n xmlns:h=\"http://www.w3.org/1999/xhtml\">\n <its:translateRule selector=\"//h:script|//h:style\" translate=\"no\"/>\n <its:translateRule selector=\"//h:del\" translate=\"no\"/>\n <its:translateRule selector=\"//h:*/@abbr|//h:*/@alt|//h:*/@prompt|//h:*/@standby|//h:*/@summary|//h:*/@title\" translate=\"yes\"/>\n <its:translateRule selector=\"//h:meta[@name='keywords']/@content\" translate=\"yes\"/>\n <its:translateRule selector=\"//h:meta[@name='description']/@content\" translate=\"yes\"/>\n <its:translateRule selector=\"//h:input/@value\" translate=\"yes\"/>\n <its:translateRule selector=\"//h:input[@type='hidden']/@value\" translate=\"no\"/>\n <its:dirRule selector=\"//h:*[@dir='ltr']\" dir=\"ltr\"/>\n <its:dirRule selector=\"//h:*[@dir='rtl']\" dir=\"rtl\"/>\n <its:idValueRule selector=\"//h:*[@id]\" idValue=\"@id\"/>\n <its:preserveSpaceRule selector=\"//h:pre|//h:textarea\" space=\"preserve\"/>\n</its:rules>"},{"title":"Quote mode configuration","description":"Configure quote escaping behavior by adding quoteModeDefined and quoteMode properties to the config file. Mode 3 escapes only double quotes.","input":"quoteModeDefined=true\nquoteMode=3"}],"filterId":"okf_html5","wikiUrl":"https://okapiframework.org/wiki/index.php/html5_its_filter"},"okf_icml":{"filterName":"ICML Filter","overview":"This filter allows you to process WCML/ICML documents. ICML (InCopy Markup Language) is an XML-based format used by Adobe InDesign. The filter handles .wcml and .icml file extensions with MIME type application/x-icml+xml. It is very similar to the IDML Filter.","parameters":{"extractNotes":{"description":"Set this option to extract the content of notes (<Note> elements) as translator notes. When enabled, note content found in the ICML document will be extracted and made available as translator notes alongside the translatable text units.","notes":[]},"extractMasterSpreads":{"description":"Set this option to extract the content of the master spreads if they exist. If this option is not set, only the normal spreads are extracted. Master spreads contain content that appears on multiple pages (e.g., headers, footers, recurring design elements).","notes":[]},"simplifyCodes":{"description":"Set this option to reduce the number of inline codes by re-grouping adjacent codes when it is possible. This simplifies the translatable segments by merging neighboring inline codes into fewer placeholders, making them easier for translators to work with.","notes":[]},"skipThreshold":{"description":"Set the maximum size for the spread files (in KBytes). Any spread file above the given value will either generate an error or will be skipped from extraction depending on the specified option. This allows you to skip over large spread files that may contain only graphics and require too much memory to be opened. Valid range is 1 to 32000 KBytes, with a default of 1000 KBytes.","notes":["Note: Skipped files are not checked for translatable text."]},"newTuOnBr":{"description":"Controls whether a Br (break / hard return) tag (<Br/> element) should create a new text unit (segment). When set to true, hard returns in the ICML content will cause the filter to split content into separate translatable segments at each break point. Default is false.","notes":[]},"moveLeadingAndTrailingCodesToSkeleton":{"description":"Move inline codes that appear at the beginning or end of a segment to the skeleton (non-translatable portion). This cleans up segments by removing formatting codes from segment boundaries, making the translatable text cleaner for translators.","notes":[]},"mergeAdjacentCodes":{"description":"Merge consecutive inline codes into a single placeholder. When multiple inline codes appear next to each other without intervening text, they are combined into one code, simplifying the segment for translation.","notes":[]},"simplifierRules":{"description":"Rules for simplifying inline code representation. These rules control how inline codes are detected, combined, and presented to translators. The rules are edited via a dedicated simplifier rules editor.","notes":[]}},"limitations":["The wiki limitations section is marked as TODO — no specific limitations are documented."],"processingNotes":["The wiki processing details section is marked as TODO — no specific processing details are documented."],"examples":[],"filterId":"okf_icml","wikiUrl":"https://okapiframework.org/wiki/index.php/icml_filter"},"okf_idml":{"filterName":"IDML Filter","overview":"The IDML filter processes IDML (InDesign Markup Language) documents, an XML-based format introduced in Adobe InDesign CS4 for representing InDesign content. IDML is used in several InDesign and InCopy file types. The filter extracts translatable text from spreads and stories within the document structure.","parameters":{"maxAttributeSize":{"description":"Set the size in bytes for the attribute buffer. The default is 4MB (4 * 1024 * 1024 = 4194304 bytes)."},"specialCharacterPattern":{"description":"A pattern defining special characters that should be treated as inline codes when matched in content. The default pattern includes various Unicode special characters such as non-breaking spaces, zero-width joiners, soft hyphens, non-breaking hyphens, and byte order marks."},"untagXmlStructures":{"description":"When enabled, embedded XML structural information is skipped when extracting translatable content. This prevents XML structure tags from appearing as inline codes in the extracted text."},"mergeAdjacentCodes":{"description":"When enabled, inline adjacent codes are merged into a single placeholder. This reduces the number of inline codes visible to translators by combining consecutive codes."},"extractNotes":{"description":"When enabled, the content of notes (<Note> elements) is extracted for translation."},"extractMasterSpreads":{"description":"When enabled, the content of master spreads is extracted if they exist. If this option is not set, only the normal spreads are extracted."},"extractHiddenLayers":{"description":"When enabled, content from hidden layers is also extracted for translation."},"extractHiddenPasteboardItems":{"description":"When enabled, content from hidden pasteboard items is extracted for translation."},"skipDiscretionaryHyphens":{"description":"When enabled, discretionary hyphens in the IDML content are skipped during extraction."},"extractBreaksInline":{"description":"When enabled, break elements are extracted inline rather than being used as text unit boundaries."},"extractHyperlinkTextSourcesInline":{"description":"When set to true, the hyperlink text sources are extracted inline. When set to false (the default), they are represented as referencing groups of textual units."},"extractCustomTextVariables":{"description":"When enabled, custom text variables defined in the IDML document are extracted for translation."},"extractIndexTopics":{"description":"When enabled, index topics in the IDML document are extracted for translation."},"extractExternalHyperlinks":{"description":"When set to true, external hyperlinks are extracted for translation."},"extractMathZones":{"description":"When set to true (the default), math zones in the document are extracted for translation."},"excludedStyleConfigurations":{"description":"Content with the specified styles is excluded from extraction. This allows you to prevent certain styled content (e.g., non-translatable labels or decorative text) from being sent for translation."},"ignoreCharacterKerning":{"description":"When enabled, character kerning differences do not cause inline code boundaries. This reduces unnecessary segmentation caused by minor kerning variations."},"characterKerningMinIgnoranceThreshold":{"description":"Minimum threshold value for ignoring character kerning. Kerning values below this threshold are ignored when determining inline code boundaries.","dependsOn":[{"property":"ignoreCharacterKerning","condition":"must be true"}]},"characterKerningMaxIgnoranceThreshold":{"description":"Maximum threshold value for ignoring character kerning. Kerning values above this threshold are ignored when determining inline code boundaries.","dependsOn":[{"property":"ignoreCharacterKerning","condition":"must be true"}]},"ignoreCharacterTracking":{"description":"When enabled, character tracking differences do not cause inline code boundaries. This reduces unnecessary segmentation caused by minor tracking variations."},"characterTrackingMinIgnoranceThreshold":{"description":"Minimum threshold value for ignoring character tracking. Tracking values below this threshold are ignored when determining inline code boundaries.","dependsOn":[{"property":"ignoreCharacterTracking","condition":"must be true"}]},"characterTrackingMaxIgnoranceThreshold":{"description":"Maximum threshold value for ignoring character tracking. Tracking values above this threshold are ignored when determining inline code boundaries.","dependsOn":[{"property":"ignoreCharacterTracking","condition":"must be true"}]},"ignoreCharacterLeading":{"description":"When enabled, character leading differences do not cause inline code boundaries. This reduces unnecessary segmentation caused by minor leading variations."},"characterLeadingMinIgnoranceThreshold":{"description":"Minimum threshold value for ignoring character leading. Leading values below this threshold are ignored when determining inline code boundaries.","dependsOn":[{"property":"ignoreCharacterLeading","condition":"must be true"}]},"characterLeadingMaxIgnoranceThreshold":{"description":"Maximum threshold value for ignoring character leading. Leading values above this threshold are ignored when determining inline code boundaries.","dependsOn":[{"property":"ignoreCharacterLeading","condition":"must be true"}]},"ignoreCharacterBaselineShift":{"description":"When enabled, character baseline shift differences do not cause inline code boundaries. This reduces unnecessary segmentation caused by minor baseline shift variations."},"characterBaselineShiftMinIgnoranceThreshold":{"description":"Minimum threshold value for ignoring character baseline shift. Baseline shift values below this threshold are ignored when determining inline code boundaries.","dependsOn":[{"property":"ignoreCharacterBaselineShift","condition":"must be true"}]},"characterBaselineShiftMaxIgnoranceThreshold":{"description":"Maximum threshold value for ignoring character baseline shift. Baseline shift values above this threshold are ignored when determining inline code boundaries.","dependsOn":[{"property":"ignoreCharacterBaselineShift","condition":"must be true"}]},"useCodeFinder":{"description":"When enabled, pattern-based detection of inline codes is activated. The patterns defined in codeFinderRules are used to identify placeholders, tags, and other non-translatable inline elements within translatable text."},"codeFinderRules":{"description":"A set of regular expression patterns used to identify inline codes (placeholders, tags, etc.) within translatable text. Each rule defines a regex pattern that, when matched, marks the matched content as an inline code rather than translatable text.","dependsOn":[{"property":"useCodeFinder","condition":"must be true"}]},"moveLeadingAndTrailingCodesToSkeleton":{"description":"When enabled, inline codes that appear at the beginning or end of a segment are moved to the skeleton (non-translatable portion). This simplifies the translatable text by removing codes that are purely structural and surround the content."},"simplifierRules":{"description":"Rules for simplifying inline code representation. These rules control how inline codes are presented to translators, reducing complexity where possible."}},"processingNotes":["The filter processes all spreads in the document, and for each spread gathers the list of stories used in <TextFrame> and <TextPath> elements.","Text is extracted by spread, and for each spread by story in the order they appear in the spread.","Stories embedded inside other stories and not declared at a spread level are extracted in a special group."],"limitations":[],"examples":[],"filterId":"okf_idml","wikiUrl":"https://okapiframework.org/wiki/index.php/idml_filter"},"okf_json":{"filterName":"JSON Filter","overview":"The JSON Filter is an Okapi component that implements the IFilter interface for JSON (JavaScript Object Notation) files. It is based on the JSON specifications (json.org) and supports extraction of translatable key-value pairs, isolated strings in arrays, inline code detection, sub-filtering, and various metadata extraction rules. The filter supports configurable key path naming, translator notes, and length restriction metadata via regex-based rules.","parameters":{"extractIsolatedStrings":{"description":"When enabled, extracts string values that are not directly associated with a key (e.g., standalone strings within arrays). By default, only key-value pair strings are candidates for extraction."},"extractAllPairs":{"description":"Controls whether all key/string pairs are extracted for translation. When set to true, all strings that have an associated key are extracted (subject to the exceptions list). When set to false, no key/string pairs are extracted by default, and only those matching the exceptions regex are extracted. This behavior is overridden by extractionRules if specified (version M39+)."},"exceptions":{"description":"A regular expression that matches keys whose extraction behavior should be the inverse of the default set by extractAllPairs. For example, if extractAllPairs is true, keys matching this regex are excluded from extraction; if extractAllPairs is false, keys matching this regex are included. When used in combination with useFullKeyPath, you can exclude nested elements with patterns like '^.*?/excludedStructure/.*'.","dependsOn":[{"property":"extractAllPairs","condition":"Behavior is inverted based on the extractAllPairs setting"}]},"useKeyAsName":{"description":"When enabled, uses the value of the JSON key as the name (resname in XLIFF) of the extracted text unit. This provides a human-readable identifier for each translatable segment."},"useFullKeyPath":{"description":"When enabled, uses the full hierarchical key path (e.g., /menu/value/popup/menuitem/value) as the resname instead of just the immediate key name. When this option is enabled, exception regular expressions also apply to the full path rather than just the key name.","dependsOn":[{"property":"useKeyAsName","condition":"must be true for this option to take effect"}]},"useLeadingSlashOnKeyPath":{"description":"When enabled, includes a leading '/' character at the beginning of the full key path. For example, '/menu/value' instead of 'menu/value'. Only relevant when useFullKeyPath is enabled.","dependsOn":[{"property":"useFullKeyPath","condition":"must be true for this option to be relevant"}]},"useIdStack":{"description":"When enabled, builds TextUnit IDs from the nested key stack, producing hierarchical identifiers for extracted segments."},"useCodeFinder":{"description":"When enabled, applies the regular expressions defined in the code finder rules to the text of extracted items. Any match is converted to an inline code (placeholder).","notes":["Note: This option cannot be used together with the sub-filtering option (subfilterRules)."]},"codeFinderRules":{"description":"Configuration for inline code detection using regular expression patterns. Each rule defines a regex pattern that, when matched within translatable text, converts the matched content into an inline code (placeholder). The default expression matches printf-style format specifiers (e.g., %s, %d), common escape sequences (\\n, \\t, etc.), and brace-delimited placeholders (e.g., {0}). Default pattern: '((%(([-0+#]?)[-0+#]?)((\\d\\$)?)(([ \\d\\*]*)(\\.[ \\d\\*]*)?)[dioxXucsfeEgGpn])|((\\\\r\\\\n)|\\\\a|\\\\b|\\\\f|\\\\n|\\\\r|\\\\t|\\\\v)|(\\{\\d.*?\\}))'","dependsOn":[{"property":"useCodeFinder","condition":"must be true for these rules to be applied"}]},"escapeForwardSlashes":{"description":"When enabled, forward slashes in the output JSON are escaped as '\\/'. This is valid JSON but not always required. Disable if the target system does not expect escaped slashes."},"noteRules":{"description":"A regular expression matching JSON key names whose values should be transferred as translator notes (<note> elements in XLIFF). For example, a regex of '/widgets/name.*' would capture values of keys matching that pattern and attach them as notes to the relevant text units.","introducedIn":"M39"},"subfilterRules":{"description":"Specifies an Okapi filter ID (e.g., 'okf_html') to process the content of all translatable text with that sub-filter. Leave blank for default behavior (no sub-filtering). This allows embedded content formats like HTML to be properly parsed within JSON string values.","notes":["Note: This option cannot be used together with the inline code finder option (useCodeFinder)."]},"extractionRules":{"description":"A regular expression matching JSON key paths whose values should be extracted for translation. When specified, this overrides the extractAllPairs and exceptions rules. For example, '/widgets/body.*' extracts only values under keys matching that pattern. Regex rules apply to key names (or full key paths if useFullKeyPath is enabled).","introducedIn":"M39","notes":["If specified, these will override the corresponding extraction rules above (extractAllPairs and exceptions)."]},"idRules":{"description":"A regular expression matching JSON key names whose values should be used as the TextUnit ID (resname in XLIFF). This overrides the useKeyAsName setting. For example, with regex 'key' and a JSON structure containing {\"key\": \"datePicker_marchMonth\", \"text\": \"March\"}, the value 'datePicker_marchMonth' becomes the resname of the text unit containing 'March'.","introducedIn":"M39","dependsOn":[{"property":"useKeyAsName","condition":"overrides useKeyAsName when specified"}]},"genericMetaRules":{"description":"A regular expression matching JSON key names whose values should be written out as <context-group> elements in XLIFF, adding them as generic metadata to the TextUnit. For example, '/widgets/image.*' would capture image-related metadata.","introducedIn":"M39"},"maxwidthRules":{"description":"A regular expression matching JSON key names whose numeric values should be extracted as the maxwidth property in XLIFF, enabling length restriction on translations. The extracted value is used as the maxwidth for all other elements of the array on the same level. Only one matching array element per hierarchy level is allowed. For nested arrays, different parent-child and sibling levels can define different maxwidth values. If no key matches on a sublevel but a key matches on a higher level, the higher-level value determines the max length for the deepest hierarchy level and its siblings without a matching key. If keys match on both higher and lower levels, all corresponding levels get their values extracted, but for higher levels the matching key must be defined after the last child element.","introducedIn":"M39"},"maxwidthSizeUnit":{"description":"The string value used as the size-unit attribute of the trans-unit in XLIFF when length restrictions are extracted via maxwidthRules. For example, 'char' or 'pixel'.","introducedIn":"M39","dependsOn":[{"property":"maxwidthRules","condition":"only relevant when maxwidthRules is specified and matches keys"}]},"moveLeadingAndTrailingCodesToSkeleton":{"description":"When enabled, moves inline codes that appear at the beginning or end of a segment to the skeleton (non-translatable portion), keeping them out of the translatable content."},"mergeAdjacentCodes":{"description":"When enabled, merges consecutive inline codes into a single placeholder, simplifying the translatable content representation."},"simplifierRules":{"description":"Rules for simplifying the inline code representation in extracted content, reducing complexity for translators."}},"limitations":["Comments within a JSON string value are parsed as part of the string content, not as comments. A configured subfilter will then process these as true comments (they will become part of the skeleton or whatever the subfilter is configured to do)."],"processingNotes":["JSON files are normally in a Unicode encoding, but the filter supports any encoding. It uses the following precedence: (1) Unicode Byte-Order-Mark if present, (2) charset declaration in the first 1000 characters, (3) the default encoding specified in filter options. If a BOM encoding and header charset conflict, a warning is generated and the BOM encoding is used.","If the output encoding is UTF-8 and the input was also UTF-8, a BOM is written only if one was detected in the input. If the input was not UTF-8, no BOM is written.","The type of line-breaks in the output matches the line-breaks of the original input.","Though not technically legal in JSON, the filter supports these comment types: // comment, # comment, /* comment */, and <!-- comment -->."],"examples":[{"title":"Basic JSON extraction","description":"A simple JSON file with nested key-value pairs. All string values associated with keys are extracted as translatable text by default.","input":"{\"menu\": {\n  \"value\": \"File\",\n  \"popup\": {\n    \"menuitem\": [\n      {\"value\": \"New\"},\n      {\"value\": \"Open\"},\n      {\"value\": \"Close\"}\n    ]\n  }\n}}","output":"Extracted translatable strings: \"File\", \"New\", \"Open\", \"Close\""},{"title":"FPRM extraction rules configuration","description":"Example of regex-based rules for extraction, notes, IDs, and metadata. Extraction rules apply to key names and override exceptions-based extraction.","input":"extractionRules=/widgets/body.*\nnoteRules=/widgets/name.*\nidRules=/widgets/id.*\ngenericMetaRules=/widgets/image.*"},{"title":"Using idRules for custom resname","description":"When JSON contains key identifiers as sibling values, idRules can map them as the resname for the translatable text unit.","input":"[\n  {\n    \"key\": \"datePicker_marchMonth\",\n    \"text\": \"March\"\n  },\n  {\n    \"key\": \"datePicker_aprilMonth\",\n    \"text\": \"April\"\n  }\n]\n\nidRules regex: key","output":"<trans-unit id=\"tu1\" resname=\"datePicker_marchMonth\" xml:space=\"preserve\">\n  <source xml:lang=\"en-US\">March</source>\n</trans-unit>\n<trans-unit id=\"tu2\" resname=\"datePicker_aprilMonth\" xml:space=\"preserve\">\n  <source xml:lang=\"en-US\">April</source>\n</trans-unit>"},{"title":"Excluding nested keys with full path regex","description":"Using useFullKeyPath in combination with an exceptions regex to exclude all nested elements under a specific structure.","input":"useFullKeyPath=true\nexceptions=^.*?/excludedStructure/.*"}],"filterId":"okf_json","wikiUrl":"https://okapiframework.org/wiki/index.php/json_filter"},"okf_markdown":{"filterName":"Markdown Filter","overview":"The Markdown Filter is an Okapi component for extracting translatable text from Markdown files. It is designed to work with markdown based on the CommonMark specification, with additional features to support GitHub-flavored Markdown. The filter supports HTML inline elements and blocks via a configurable HTML subfilter, YAML metadata headers via a configurable YAML subfilter, and includes an Inline Code Finder for pattern-based detection of inline codes.","parameters":{"htmlSubfilter":{"description":"The custom configuration ID of the HTML filter that will be called to process HTML contents within Markdown documents. The configuration file must be saved in a known location with '.fprm' suffix. Specify nothing (empty string) to use the default HTML filter configuration tailored for the Markdown filter.","notes":["The HTML subfilter processes both HTML Inline Elements (tags) and HTML Blocks (text sandwiched between a block-forming start tag and its corresponding end tag).","To enable inline code patterns for the HTML filter separately, name the configuration as okf_html@arbitrary-name.fprm and specify that name for this parameter."]},"yamlSubfilter":{"description":"The custom configuration ID of the YAML filter that will be called to process any YAML metadata header detected in the document. This allows for customization of the metadata fields extracted for translation. Specify nothing (empty string) to use the default YAML filter configuration."},"useCodeFinder":{"description":"Determines whether to use the Inline Code Finder or not. When enabled, the filter uses regex-based pattern matching to identify inline codes (placeholders, tags, etc.) in translatable text. The Inline Code Finder applies to the translatable text within the proper part of the Markdown document; it does not apply to HTML inline tags or HTML blocks.","notes":["The Inline Code Finder does not apply to HTML inline tags or HTML blocks. For those, you need to enable and specify the inline code pattern for the HTML filter separately.","Support of the Inline Code Finder was temporarily unavailable in some snapshot builds of version 0.36, but it has been restored."]},"codeFinderRules":{"description":"Configuration for the Inline Code Finder rules. Contains a list of regex patterns used to identify inline codes in translatable text, a sample text field for testing patterns in the UI, and a flag controlling whether all rules are applied together when testing.","dependsOn":[{"property":"useCodeFinder","condition":"must be true for these rules to take effect"}]},"translateUrls":{"description":"Controls whether URLs in link and image statements are exposed for translation. By default, URLs are not extracted. When enabled, URLs will be extracted as a subflow. When a subflow of text occurs in the middle of main text, the subflow is extracted before the segment that contains it."},"translateCodeBlocks":{"description":"Controls whether the contents of fenced code blocks are exposed for translation. Fenced code blocks are delimited by triple backticks or tildes."},"translateIndentedCodeBlocks":{"description":"Controls whether the contents of indented code blocks (blocks indented by four spaces or one tab) are exposed for translation."},"translateInlineCodeBlocks":{"description":"Controls whether the contents of inline code blocks (text delimited by single backticks) are exposed for translation."},"translateHeaderMetadata":{"description":"Controls whether the YAML Metadata Header is exposed for translation. Some markdown formats support a YAML Metadata Header (as defined by Pandoc's yaml_metadata_block extension) that contains key/value data. When enabled, the header will be parsed and the metadata values will be exposed for translation."},"translateImageAltText":{"description":"Controls whether the alt text for graphic images is extracted for translation. This applies to both Markdown image syntax (e.g., ![alt text](url)) and HTML img tags with alt attributes (e.g., <img src=\"url\" alt=\"alt text\">)."},"urlToTranslatePattern":{"description":"A regular expression pattern that controls which URLs are extracted for translation when translateUrls is enabled. Only URLs matching this pattern will be extracted. The default value '.+' matches all URLs.","dependsOn":[{"property":"translateUrls","condition":"must be true for this pattern to take effect"}]},"htmlEntitiesToEscape":{"description":"A string of characters that will be encoded as HTML entities on export. Each character in the string will be escaped individually. Specify an empty string for no escaping."},"nonTranslateBlocks":{"description":"Prevents certain block quotes from being extracted for translation. Block quotes that start with one of the comma-separated strings specified in this option will not be extracted. An empty value means all block quote contents will be extracted."},"unescapeBackslashCharacters":{"description":"Controls whether the filter parses backslash-escaped punctuation in source documents. When enabled, backslash-escaped punctuation characters will be processed during parsing, and the characters listed in 'charactersToEscape' will be backslash-escaped on export."},"charactersToEscape":{"description":"When 'unescapeBackslashCharacters' is enabled, characters listed in this string will be backslash-escaped on export. Each character in the string is treated individually. The default value covers common Markdown special characters: *_`{}[]<>()#+\\-.!|","dependsOn":[{"property":"unescapeBackslashCharacters","condition":"must be true for these characters to be escaped on export"}]},"generateHeaderAnchors":{"description":"Some markdown parsers support explicit named anchors in header markup, using the syntax {#my-anchor}. When enabled, this option will automatically generate anchors for headings in the source document, for the purpose of providing a stable anchor for hyperlinks that reference a translatable header value."},"parseMdx":{"description":"Experimental feature. When enabled, parses out multi-line 'export' blocks as skeleton using regex. This is intended for MDX files that mix Markdown with JSX expressions.","notes":["This feature is marked as experimental."]}},"processingNotes":["If the file has a Unicode Byte-Order-Mark (BOM), the corresponding encoding (e.g. UTF-8, UTF-16) is used. Otherwise, the default encoding specified in the filter options is used.","HTML Inline Elements (tags) and HTML Blocks (text between block-forming start/end tags) are processed by the HTML subfilter. The HTML filter used can be customized separately via the htmlSubfilter parameter.","The Inline Code Finder applies only to translatable text within the Markdown document proper. It does not apply to HTML inline tags or HTML blocks — those require separate inline code pattern configuration in the HTML subfilter."],"examples":[{"title":"URL Subflow Extraction","description":"When translateUrls is enabled, URLs in image/link statements are extracted as subflows before the segment containing them. This example shows how an image with alt text and URL is decomposed into separate translation units.","input":"Please click ![The Information desk logo](images/circled-i.jpg) for help.","output":"<trans-unit id=\"tu2\" restype=\"x-img-link\" xml:space=\"preserve\">\n<source xml:lang=\"en\">images/circled-i.jpg</source>\n</trans-unit>\n<trans-unit id=\"tu1\" xml:space=\"preserve\">\n<source xml:lang=\"en\">Please click <bpt id=\"1\">![</bpt>The Information desk logo<ept id=\"1\">]([#$tu2])</ept> for help.</source>\n</trans-unit>"}],"limitations":[],"filterId":"okf_markdown","wikiUrl":"https://okapiframework.org/wiki/index.php/markdown_filter"},"okf_messageformat":{"filterName":"Message Format Filter","overview":"The MessageFormatFilter is designed to handle message formats commonly found in software applications, including ICU Message Format and Java MessageFormat. This filter is meant to be used as a subfilter, where the message strings can reside in various container formats such as JSON, YAML, XML, etc.","parameters":{"addPluralForms":{"description":"When enabled, new plural forms will be added based on the target locale. The source string is modified and then refiltered to provide the new plural forms to the translator. Default is false.","notes":[]},"normalize":{"description":"When enabled, the source will be normalized to move leading and trailing text inside each complex variant (plural, select, etc.). This makes translation easier by forcing each variant to be a complete phrase or sentence. Default is false.","notes":["This option can increase word and character counts for the source!"]},"prettyPrint":{"description":"When enabled, the output is formatted to enhance readability. Any whitespace added is not significant. When disabled (the default), the filter returns a compact string, normally a single line. Default is false.","notes":[]},"useCodeFinder":{"description":"Enable pattern-based detection of inline codes (placeholders, tags, etc.) within translatable text.","notes":[]},"codeFinderRules":{"description":"Regex patterns to identify inline codes in translatable text. Contains a list of regex rules, a sample string for testing, and an option to test all rules together or individually.","dependsOn":[{"property":"useCodeFinder","condition":"must be true"}],"notes":[]},"mergeAdjacentCodes":{"description":"Merge consecutive inline codes into a single placeholder to simplify the translatable content.","dependsOn":[{"property":"useCodeFinder","condition":"must be true"}],"notes":[]},"moveLeadingAndTrailingCodesToSkeleton":{"description":"Move inline codes at segment boundaries to the skeleton (non-translatable portion), removing them from the translatable text.","dependsOn":[{"property":"useCodeFinder","condition":"must be true"}],"notes":[]},"simplifierRules":{"description":"Rules for simplifying inline code representation in translatable text.","dependsOn":[{"property":"useCodeFinder","condition":"must be true"}],"notes":[]}},"limitations":["The 'choice' syntax is not supported. For example: \"The value {count, choice, 0 #is none |1 #is one |1 <is more than one}\". This syntax is deprecated and should be converted to 'select' or 'plural'."],"processingNotes":["This filter is designed to be used as a subfilter; message strings should come from a container format (JSON, YAML, XML, etc.).","The normalize option modifies source strings to move leading and trailing text inside each complex variant (plural, select), which can increase word and character counts.","The prettyPrint option adds non-significant whitespace for readability; the default compact output is normally a single line."],"examples":[],"filterId":"okf_messageformat","wikiUrl":"https://okapiframework.org/wiki/index.php/message_format_filter"},"okf_mif":{"filterName":"MIF Filter","overview":"This filter allows you to process MIF (Maker Interchange Format) documents generated and read by Adobe FrameMaker. The specification for MIF 9.0 can be found on the Adobe Web site. The filter automatically detects encoding based on the file version and supports extraction from different page types (body, master, reference, hidden) as well as variables, index markers, and links.","parameters":{"extractBodyPages":{"description":"Set this option to extract the body pages of the MIF document."},"extractReferencePages":{"description":"Set this option to extract the reference pages. Note that by default FrameMaker creates its new documents with several reference pages that contain text."},"extractMasterPages":{"description":"Set this option to extract the master pages."},"extractHiddenPages":{"description":"Set this option to extract the hidden pages."},"extractVariables":{"description":"Set this option to extract the definitions of the variables."},"extractIndexMarkers":{"description":"Set this option to extract the index markers in the extractable pages. The text of each index entry is extracted in a separate text unit, before the text unit that contains the index marker."},"extractLinks":{"description":"Set this option to extract URLs of the links in the extractable pages. Each URL is extracted in a separate text unit, before the text unit that contains the hypertext marker."},"useCodeFinder":{"description":"Set this option to use the specified regular expressions on the text of the extracted items. Any match will be converted to an inline code. By default the expression is: <\\$.*?>"},"codeFinderRules":{"description":"Regular expression patterns applied to the text of extracted items. Any match is converted to an inline code. The default pattern is <\\$.*?> which matches FrameMaker variable references in the text."},"extractPgfNumFormatsInline":{"description":"Controls whether paragraph number formats are extracted as inline content."},"extractReferenceFormats":{"description":"Controls whether reference formats are extracted."},"extractHardReturnsAsText":{"description":"Controls whether hard returns in MIF content are extracted as text."},"moveLeadingAndTrailingCodesToSkeleton":{"description":"Move inline codes at segment boundaries to the skeleton (non-translatable portion), removing them from the translatable text units."},"mergeAdjacentCodes":{"description":"Merge consecutive inline codes into a single placeholder to simplify the translatable text."},"simplifierRules":{"description":"Rules for simplifying inline code representation in the extracted text."}},"limitations":["Versions older than MIF 8.0 are not supported.","You may run into Java heap memory issues if the document includes very large embedded insets (e.g. images). The workaround is to link to external objects rather than embed them.","The filter does not do font mapping yet, so if the translated file is in a language not supported by the fonts used in the source document, you need to update the paragraph and character catalogs to use fonts providing the proper support."],"processingNotes":["The encoding of the input MIF document is automatically detected based on the version of the file and different other information in the document.","MIF v8 and above use UTF-8 for both input and output encoding.","MIF v8 and above are automatically output in UTF-8."],"examples":[{"title":"Default inline code pattern","description":"The default code finder regular expression pattern matches FrameMaker variable references embedded in text.","input":"<$.*?>"}],"filterId":"okf_mif","wikiUrl":"https://okapiframework.org/wiki/index.php/mif_filter"},"okf_mosestext":{"filterName":"Moses Text Filter","overview":"The Moses Text Filter processes InlineText files used by the Moses MT system. Each line in the file is read as a separate text unit, with inline codes represented by elements like &lt;g id=\"N\"&gt;, &lt;x id=\"N\"&gt;, &lt;bx id=\"N\"&gt;, and &lt;ex id=\"N\"&gt;, and line-breaks represented by &lt;lb/&gt;. The filter is typically used in conjunction with the Moses InlineText Extraction Step and Moses InlineText Leveraging Step to round-trip translations through the Moses pipeline.","parameters":{},"limitations":["None known."],"processingNotes":["If the document has a BOM, it is used to determine the input encoding; otherwise UTF-8 is used as the default encoding regardless of any specified default encoding.","The output encoding is always forced to UTF-8.","The type of line-breaks in the output matches the original input.","Reading a Moses InlineText file may yield more text units than the original document because each segment (or unsegmented text unit) of the original document is extracted as a single entry in the Moses file, and the Moses file has no way to mark that several entries belong to the same original text unit.","To know exactly which original text unit a Moses file entry corresponds to, both the original file and its corresponding Moses file must be processed together (e.g., using the Moses InlineText Leveraging Step)."],"examples":[{"title":"Moses InlineText file format","description":"Example of a Moses InlineText file with four entries (lines). Translatable text is interspersed with inline codes. Inline codes use <g id=\"N\">, <x id=\"N\"/>, <bx id=\"N\">, and <ex id=\"N\"> elements. Line-breaks within an entry are represented by <lb/>.","input":"Text in the first entry.\nText of the second entry<lb/>which spans<lb/>several lines\nThird entry.\nFourth entry with <g id=\"1\">bold words</g> and some code:<x id=\"2\"/>"}],"filterId":"okf_mosestext","wikiUrl":"https://okapiframework.org/wiki/index.php/moses_text_filter"},"okf_multiparsers":{"filterName":"Multi-Parsers Filter","overview":"The Multi-Parsers Filter is an Okapi component for extracting translatable text from two-level complex formats. For example, it can process a CSV file where some columns contain Markdown, some HTML, and some plain text. By default, the filter settings are configured to process a CSV file where all columns are translatable and contain plain text.","parameters":{"csvNoExtractCols":{"description":"A comma-separated list of column indices that should not be extracted for translation. Columns are zero-indexed (the first column is 0). Any columns listed here will be skipped during extraction.","dependsOn":[{"property":"csvAutoDetectColumnTypes","condition":"must be false (disabled) for this parameter to take effect"}]},"csvFormatCols":{"description":"A comma-separated list of columns that contain non-plain-text content, with each entry specifying the column index and the sub-filter to use, in the format 'columnIndex:filterId'. Columns are zero-indexed (the first column is 0). For example, '3:okf_markdown' indicates that column 3 should be processed with the Markdown filter. Columns not listed here are treated as plain text by default.","dependsOn":[{"property":"csvAutoDetectColumnTypes","condition":"must be false (disabled) for this parameter to take effect"}]},"csvStartingRow":{"description":"The row number at which text extraction starts. Rows are one-indexed (the first row is 1). Rows before this number are skipped. This is useful for skipping header rows in CSV files. Valid range is 1 to 9999999.","dependsOn":[{"property":"csvAutoDetectColumnTypes","condition":"must be false (disabled) for this parameter to take effect"}]},"csvAutoDetectColumnTypes":{"description":"When enabled, the filter uses auto-detection based on a special configuration row embedded within each input file, rather than relying on the manually configured column settings (csvNoExtractCols, csvFormatCols, csvStartingRow). When this is true, the manual column configuration parameters are ignored and the filter reads column type information from the row specified by csvAutoDetectColumnTypesRow."},"csvAutoDetectColumnTypesRow":{"description":"The row number in the input file that contains the special configuration information for auto-detecting column types. Rows are one-indexed (the first row is 1). Valid range is 1 to 9999999. This row is read by the filter to determine how each column should be processed.","dependsOn":[{"property":"csvAutoDetectColumnTypes","condition":"must be true (enabled) for this parameter to take effect"}]}},"limitations":["This filter is BETA."],"processingNotes":["If the input file has a Unicode Byte-Order-Mark (BOM), the corresponding encoding (e.g. UTF-8, UTF-16, etc.) is used automatically.","If no BOM is present, the input encoding defaults to the encoding specified when setting the filter options."],"examples":[],"filterId":"okf_multiparsers","wikiUrl":"https://okapiframework.org/wiki/index.php/multi_parsers_filter"},"okf_odf":{"filterName":"OpenOffice Filter (ODF)","overview":"The OpenOffice Filter is an Okapi component that implements the IFilter interface for OpenOffice.org documents: ODT (text), ODS (spreadsheet), ODP (slides), ODG (graphics), and their corresponding template formats. These documents use the OpenDocument format (ODF). If you need to process directly an XML ODF file, you can use the ODF Filter that the OpenOffice Filter uses internally.","parameters":{"extractNotes":{"description":"Set this option to extract the content of <office:annotation> elements (notes) as translatable text. If this option is not set, notes are not extracted.","notes":["The option to extract or not the notes is not working yet — notes will be extracted regardless of the option setting."]},"extractReferences":{"description":"Set this option to extract the content of <text:bookmark-ref> elements. The content of these elements is only a copy of the content of the referent. It is updated automatically within OpenOffice, so any translation done for this content will be automatically overwritten as soon as the document is updated. However, in some cases it may be useful to have the referenced text as part of the segment where it is inserted.","notes":["The option to extract or not the references is not working yet — they will be extracted regardless of the option setting.","Translated content for bookmark references will be automatically overwritten when the document is updated in OpenOffice."]},"extractMetadata":{"description":"Extract metadata found in meta.xml for translation. Enabled by default (true)."},"encodeCharacterEntityReferenceGlyphs":{"description":"Encode character entity reference glyphs. Enabled by default (true)."},"moveLeadingAndTrailingCodesToSkeleton":{"description":"Move inline codes at segment boundaries to the skeleton (non-translatable). This removes leading and trailing inline codes from the translatable content and places them in the surrounding non-translatable skeleton."},"mergeAdjacentCodes":{"description":"Merge consecutive inline codes into a single placeholder. When enabled, adjacent inline codes are combined to simplify the translatable content."},"simplifierRules":{"description":"Rules for simplifying inline code representation. Defines how complex inline codes are simplified into more manageable placeholders for translators."}},"limitations":["Some deleted text may get extracted. Make sure you have accepted or rejected the revision changes before processing the input document, as currently some text marked as deleted is still extracted.","The options to extract or not the notes and the references are not working yet. They will be extracted regardless of the option settings.","Sequential tabs may get reduced to a single tab during an extraction and merge round trip: the elements for spaces and tabs are supported in output but still incorrectly handled on input.","The target (output) encoding must be set to UTF-8 when extracting the documents to merge them back properly."],"processingNotes":["Input encoding is automatically detected.","Any user-specified output encoding is ignored — the filter always uses UTF-8.","Line-breaks in the output are always set to a simple linefeed (LF).","An OpenOffice document is a ZIP file with several embedded documents. The main one (content.xml) contains the body of the data, but meta.xml and style.xml may also contain translatable text.","All embedded files are treated as sub-documents. For example, when extracted to XLIFF, a single ODT produces three XLIFF <file> elements: one for content.xml, one for style.xml, and one for meta.xml. Very often, only content.xml has extracted text."],"examples":[],"filterId":"okf_odf","wikiUrl":"https://okapiframework.org/wiki/index.php/openoffice_filter"},"okf_openxml":{"filterName":"OpenXML Filter","overview":"This filter processes Microsoft Office documents from 2007 and later, including DOCX (text documents), XLSX (spreadsheets), and PPTX (presentations). These documents are based on the OpenXML format, as opposed to the binary formats used by pre-2007 versions of Office. The filter parameters are divided into General Options that apply to all formats, and format-specific options for Word, Excel, and PowerPoint.","parameters":{"bPreferenceTranslateDocProperties":{"description":"When enabled, exposes the following document properties for translation: title, subject, creator, description, category, keywords, content status. This is a general option that applies to all Office document types."},"translatePowerpointDocProperties":{"description":"When enabled and the general 'Translate Document Properties' option is also enabled, the following PowerPoint document properties are exposed for translation: title, subject, creator, description, category, keywords, content status. Both this option and the general document properties option must be checked for PowerPoint document properties to be extracted.","notes":["The PowerPoint-specific option requires the general 'Translate Document Properties' option to also be enabled. They will be separated after the next release."],"dependsOn":[{"property":"bPreferenceTranslateDocProperties","condition":"must be true for PowerPoint document properties to be extracted"}]},"reorderPowerpointDocProperties":{"description":"When enabled, the PowerPoint document properties are reordered and placed after the root relationship part (_rels/.rels)."},"reorderPowerpointRelationships":{"description":"When enabled, the PowerPoint relationship parts are reordered and placed after the related slide or layout or master part."},"translatePowerpointDiagramData":{"description":"When enabled, the PowerPoint diagram data are exposed for translation."},"reorderPowerpointDiagramData":{"description":"When enabled, the diagram data parts are reordered and placed after the related slide or layout or master part and after their relationship parts."},"translatePowerpointCharts":{"description":"When enabled, the PowerPoint charts are exposed for translation."},"reorderPowerpointCharts":{"description":"When enabled, the chart parts are reordered and placed after the related slide or layout or master part and after their diagram data parts."},"bPreferenceTranslateComments":{"description":"When enabled, exposes document comments for translation. This is a general option that applies to all Office document types."},"translatePowerpointComments":{"description":"When enabled and the general 'Translate Comments' option is also enabled, PowerPoint document comments are exposed for translation.","notes":["The PowerPoint-specific option requires the general 'Translate Comments' option to also be enabled. They will be separated after the next release."],"dependsOn":[{"property":"bPreferenceTranslateComments","condition":"must be true for PowerPoint comments to be extracted"}]},"reorderPowerpointComments":{"description":"When enabled, the comment parts are reordered and placed after the related slide part and after its note parts."},"bPreferenceAggressiveCleanup":{"description":"When enabled, strips additional formatting tags related to text spacing. This is meant to improve filtering in cases where Office documents were converted from other formats (in particular, PDF), and imperfect conversion added a lot of extra formatting noise."},"ignoreWhitespaceStyles":{"description":"When enabled under the 'Clean Tags Aggressively' option, whitespace character styles (formatting) are ignored and considered equal to the consequential ones.","dependsOn":[{"property":"bPreferenceAggressiveCleanup","condition":"must be true for this option to take effect"}]},"preserveAsciiAndHighAnsiFontCategoriesOnDetection":{"description":"When enabled, the ASCII and HighAnsi run font categories are preserved on the merge of consequential runs."},"removeEmbeddedExcel":{"description":"When enabled, and either cached chart strings or numbers are also set for extraction, the embedded Excel package is removed, and any references to it in chart parts and related relationships are removed as well.","dependsOn":[{"property":"translatePowerpointCachedChartStrings","condition":"must be true, or translatePowerpointCachedChartNumbers must be true, for this option to have effect"}]},"bPreferenceAutomaticallyAcceptRevisions":{"description":"When enabled, tracked revisions are automatically accepted during processing."},"bPreferenceTranslatePowerpointNotes":{"description":"When enabled, slide notes in PowerPoint presentations are exposed for translation."},"bPreferenceReorderPowerpointNotes":{"description":"When enabled, the note parts are reordered and placed after the related slide part and after its chart parts."},"bPreferenceTranslatePowerpointMasters":{"description":"When enabled, exposes slide masters and notes masters for translation. This will also expose for translation content from layouts that are currently in use by at least one slide."},"bPreferenceIgnorePlaceholdersInPowerpointMasters":{"description":"When enabled, placeholder text in PowerPoint slide masters is ignored and not exposed for translation."},"bPreferenceTranslateWordHeadersFooters":{"description":"When enabled, exposes header and footer content in Word documents for translation."},"translateWordNumberingLevelText":{"description":"When enabled, exposes numbering-level text in Word documents for translation."},"bPreferenceTranslateWordHidden":{"description":"When enabled, exposes hidden text in Word documents for translation."},"bPreferenceTranslateExcelExcludeColors":{"description":"When enabled, text with a foreground or background color matching any of the selected colors will be excluded from translation in Excel workbooks. The named colors available in the UI correspond to the standard color palette of Excel 2010. The configuration also supports colors specified as RGB in the format RRGGBB, so specific colors not explicitly listed in the UI may be excluded by modifying the .fprm file by hand.","notes":["Colors can be specified as RGB hex strings (RRGGBB format) by modifying the .fprm configuration file directly. For example, to exclude #69b3e7 (Pantone 292), modify the tsExcelExcludedColors section."]},"bPreferenceTranslateExcelSheetNames":{"description":"When enabled, exposes Excel worksheet/sheet names for translation."},"translateExcelCellsCopied":{"description":"When enabled, cell data are copied on extraction to allow contextualised and independent translations."},"bPreferenceTranslateExcelDiagramData":{"description":"When enabled, exposes Excel diagram data for translation."},"bPreferenceTranslateExcelDrawings":{"description":"When enabled, exposes text from shapes and drawings in Excel workbooks for translation."},"bPreferenceTranslatePowerpointHidden":{"description":"When enabled, exposes hidden content in PowerPoint presentations for translation."},"bPreferenceTranslateWordExcludeGraphicMetaData":{"description":"When enabled, excludes graphic metadata from translation in Word documents."},"translateWordGraphicName":{"description":"When enabled, @name attribute values associated with drawings and word art in Word documents are exposed for translation."},"translateWordGraphicDescription":{"description":"When enabled, @descr attribute values associated with drawings and word art in Word documents are exposed for translation."},"translatePowerpointGraphicName":{"description":"When enabled, @name attribute values associated with drawings and word art in PowerPoint presentations are exposed for translation."},"translatePowerpointGraphicDescription":{"description":"When enabled, @descr attribute values associated with drawings and word art in PowerPoint presentations are exposed for translation."},"translatePowerpointCachedChartStrings":{"description":"When enabled, the cached chart strings in PowerPoint presentations are exposed for translation."},"translatePowerpointCachedChartNumbers":{"description":"When enabled, the cached chart numbers and format codes in PowerPoint presentations are exposed for translation."},"bPreferenceTranslateExcelHidden":{"description":"When enabled, hidden rows and columns in Excel workbooks are exposed for translation."},"bExtractExternalHyperlinks":{"description":"When enabled, external hyperlinks are extracted for translation."},"bInExcludeMode":{"description":"Controls whether the style-based filtering operates in exclude or include mode. When true (Exclude mode), text using any selected styles will be excluded from translation. When false (Include mode), only text using the selected styles will be included for translation.","notes":["Text that is excluded using this mechanism will be treated as hidden; the 'Translate Everything Hidden' options will extract it."]},"bInExcludeHighlightMode":{"description":"Controls whether highlight color-based filtering operates in exclude or include mode. When true (Exclude mode), all content except for text in the specified highlight colors will be extracted for translation. When false (Include mode), only text in the specified highlight colors will be extracted for translation. Default: set to Exclude with no colors selected, meaning all visible content will be extracted.","notes":["Text that is excluded using this mechanism will be treated as hidden; the 'Translate Everything Hidden' options will extract it.","Starting in 1.48.0, this option also applies to content in PowerPoint files."],"introducedIn":"1.48.0"},"bPreferenceTranslateWordExcludeColors":{"description":"When enabled, text using any selected font colours in Word documents will not be exposed for translation."},"bPreferenceAddTabAsCharacter":{"description":"When enabled, tab characters are added as inline character codes rather than being represented as tags."},"bPreferenceAddLineSeparatorAsCharacter":{"description":"When enabled, line separator elements are added as inline character codes rather than being represented as tags."},"sPreferenceLineSeparatorReplacement":{"description":"Specifies the replacement string to use for line separator elements when they are represented as characters. Default value is a newline character (\\n).","dependsOn":[{"property":"bPreferenceAddLineSeparatorAsCharacter","condition":"must be true for this replacement to be applied"}]},"bPreferenceReplaceNoBreakHyphenTag":{"description":"When enabled, no-break hyphen tags are replaced with the corresponding character."},"bPreferenceIgnoreSoftHyphenTag":{"description":"When enabled, soft hyphen tags are ignored during processing."},"bPreferencePowerpointIncludedSlideNumbersOnly":{"description":"When enabled, only slides with numbers specified in the included slides list are processed for translation."},"bReorderPowerpointNotesAndComments":{"description":"When enabled, PowerPoint notes and comments parts are reordered together."},"ignoreWordFontColors":{"description":"When enabled, font colours in Word documents will be ignored during processing. If 'Clean Tags Aggressively' and this option are both enabled and the ignorance thresholds are empty, the font colour run properties are removed from the document structure on filtering, meaning the font colour information is absent on merge as well.","notes":["If Clean Tags Aggressively and this option are both checked with empty thresholds, font colour run properties are permanently removed from the document structure."],"dependsOn":[{"property":"bPreferenceAggressiveCleanup","condition":"when both are true and thresholds are empty, font colour run properties are removed from document structure"}]},"wordFontColorsMinIgnoranceThreshold":{"description":"When defined, font colours will be ignored starting from the specified value. Can be empty (considered as a white colour by default), or contain preset colour values or RGB hex strings. Valid values include: black, Black, 000000 (thresholds in black). Accepts both named color presets and RGB hex strings.","dependsOn":[{"property":"ignoreWordFontColors","condition":"must be true for this threshold to take effect"}]},"wordFontColorsMaxIgnoranceThreshold":{"description":"When defined, font colours will be ignored ending by the specified value. Can be empty (considered as a white colour by default), or contain preset colour values or RGB hex strings. Valid values include: white, White, FFFFFF (thresholds in white). Accepts both named color presets and RGB hex strings.","dependsOn":[{"property":"ignoreWordFontColors","condition":"must be true for this threshold to take effect"}]},"allowWordStyleOptimisation":{"description":"When enabled, optimisation of Word styles is allowed — common formatting of all runs in a paragraph is moved to the styles part."},"preserveExcelStylesInTargetColumns":{"description":"When enabled, the cell styles in Excel target columns are preserved during merge."},"treatExcelSourceColumnStylesForExclusion":{"description":"When enabled, source column styles are considered for exclusion criteria in Excel worksheets."},"extractExcelSourceAndTargetColumnsJoined":{"description":"When enabled, the source and target columns (cells in a row) are joined on extraction in Excel worksheets."},"extractExcelWorksheetsExplicitlySpecified":{"description":"When enabled, only worksheets that match their names in the Worksheet Configurations are exposed for extraction."},"extractExcelCellsExplicitlySpecified":{"description":"When enabled, only cells specified in the Worksheet Configurations are exposed for extraction. The explicitly mentioned source and target columns are eligible for such handling."},"bPreferenceAllowEmptyTargets":{"description":"When enabled, allows empty target segments to be written during merge without falling back to the source text."},"useCodeFinder":{"description":"When enabled, activates pattern-based detection of inline codes (placeholders, tags, etc.) using the rules defined in the code finder configuration."},"codeFinderRules":{"description":"Configuration for inline code detection. Contains a list of regex patterns that define what constitutes an inline code (placeholder, tag, etc.) within translatable text. Each rule specifies a regex pattern, and a sample text can be provided to test the patterns. When useAllRulesWhenTesting is enabled, all rules are tested together against the sample.","dependsOn":[{"property":"useCodeFinder","condition":"must be true for these rules to be applied"}]},"moveLeadingAndTrailingCodesToSkeleton":{"description":"When enabled, inline codes at segment boundaries (leading and trailing) are moved to the skeleton, making them non-translatable. This reduces clutter in translatable segments."},"mergeAdjacentCodes":{"description":"When enabled, consecutive inline codes are merged into a single placeholder, simplifying the translatable segment."},"simplifierRules":{"description":"Rules for simplifying inline code representation within translatable segments. Allows defining how complex inline formatting codes are simplified for cleaner presentation to translators."},"nFileType":{"description":"Specifies the type of Office file being processed. Valid values are: MSWORD (Word documents), MSEXCEL (Excel spreadsheets), MSWORDDOCPROPERTIES (Word document properties), MSPOWERPOINTCOMMENTS (PowerPoint comments)."},"maxAttributeSize":{"description":"Maximum size in bytes for XML attributes during processing. Default is 4194304 (4 MB)."}},"limitations":["Various known issues exist; see the Okapi Bitbucket issues list filtered by OpenXML."],"processingNotes":["The filter processes OpenXML-based Office documents (2007+), not the binary formats used by pre-2007 versions of Office.","When 'Clean Tags Aggressively' and 'Ignore Font Colours' are both enabled with empty ignorance thresholds, font colour run properties are permanently removed from the document structure — this information will be absent on merge.","Excel color exclusion supports both named colors from the Excel 2010 standard palette (via UI) and RGB hex strings in RRGGBB format (via direct .fprm file editing).","PowerPoint document properties and comments options currently require the corresponding General Options to also be enabled; they will be separated in a future release.","Text excluded via highlight colors or styles is treated as hidden and can still be extracted if the corresponding 'Translate Hidden' option is enabled."],"examples":[{"title":"Excel Worksheet Configuration: Source/Target Columns with Excluded Rows","description":"Configures extraction to translate column A, place translations in column B, exclude rows 1-2 (headers), and exclude columns C-D from translation.","input":"worksheetConfigurations.number.i=1\nworksheetConfigurations.0.namePattern=Sheet1\nworksheetConfigurations.0.sourceColumns=A\nworksheetConfigurations.0.targetColumns=B\nworksheetConfigurations.0.excludedRows=1,2\nworksheetConfigurations.0.excludedColumns=C,D","output":"After extraction and merge, column B contains translations of column A (e.g., A3→A3-tr, A4→A4-tr, A5→A5-tr), while rows 1-2 and columns C-D remain unchanged."},{"title":"Excel Worksheet Configuration: Metadata Rows and Columns","description":"Configures extraction to translate columns A and B, treat column D as metadata for each translatable cell in a row, treat rows 1-2 as metadata headers, and exclude row 5 and column C.","input":"worksheetConfigurations.number.i=1\nworksheetConfigurations.0.namePattern=Sheet1\nworksheetConfigurations.0.excludedRows=5\nworksheetConfigurations.0.excludedColumns=C\nworksheetConfigurations.0.metadataRows=1,2\nworksheetConfigurations.0.metadataColumns=D","output":"In the extracted XLIFF, rows 3-4 contain trans-units for cells A3, B3, A4, B4 with context-group elements containing metadata from column D. Metadata row headers from rows 1-2 are used as context-type labels. Row 5 is excluded entirely."},{"title":"Excel Custom RGB Color Exclusion","description":"Demonstrates how to exclude a specific RGB color (#69b3e7, Pantone 292) from translation by editing the .fprm configuration file directly, using RRGGBB hex format.","input":"tsExcelExcludedColors.i=1\nccc0=69b3e7","output":"Cells with foreground or background color #69b3e7 will be excluded from translation."}],"filterId":"okf_openxml","wikiUrl":"https://okapiframework.org/wiki/index.php/openxml_filter"},"okf_pdf":{"filterName":"PDF Filter","overview":"The PDF Filter is an Okapi component that implements the IFilter interface for PDF files. It does not deal with complex formatting like tables or multi-level lists. The typical use case is to scrape text from PDF for quick and dirty word counts and leverage analysis. This filter does not merge back into PDF format; instead it produces a plain text file output upon merging.","parameters":{"useCodeFinder":{"description":"Enable pattern-based detection of inline codes (placeholders, tags, etc.). The wiki states this filter has no parameters, so this is inherited from the framework's generic inline code handling rather than being a PDF-filter-specific option."},"indentThreshold":{"description":"The amount of indent needed to define a new paragraph. Specified as a decimal number string. Default value is '2.0'."},"spacingTolerance":{"description":"The amount of spacing needed to define a white space character. Specified as a decimal number string. Default value is '0.5'."},"preserveWhitespace":{"description":"When enabled, preserves the original whitespace in extracted text rather than normalizing it. Default is false."},"lineSeparator":{"description":"The character to use as a line separator in the extracted text. Default is a newline character ('\\n')."},"paragraphSeparator":{"description":"The character to use as a paragraph separator in the extracted text. Default is a newline character ('\\n')."},"sortByPosition":{"description":"When enabled, sorts the extracted text by position within the document. This can be useful when the PDF's internal text order does not match the visual reading order. Default is false."},"moveLeadingAndTrailingCodesToSkeleton":{"description":"Move inline codes that appear at the beginning or end of a segment to the skeleton (non-translatable part), keeping them out of the translatable text."},"mergeAdjacentCodes":{"description":"Merge consecutive inline codes into a single placeholder to simplify the translatable content."},"simplifierRules":{"description":"Rules for simplifying inline code representation. Allows defining patterns to reduce complex inline code sequences into simpler placeholders for easier translation."}},"limitations":["This filter merges back in plain text format, not PDF.","Does not deal with complex formatting like tables, multi-level lists, etc."],"processingNotes":["PDF files are binary files and do not have a specific encoding. Okapi extracts all text from the PDF as a Java string and forces the encoding to be 'UTF-16'. Any encoding selected in tools like Rainbow will be ignored.","TextUnits are created following the default rules of the Plain Text filter. Any text followed by a newline will create a new TextUnit or paragraph."],"examples":[],"filterId":"okf_pdf","wikiUrl":"https://okapiframework.org/wiki/index.php/pdf_filter"},"okf_pensieve":{"filterName":"Pensieve TM Filter","overview":"The Pensieve TM Filter is an Okapi component that implements the IFilter interface for Pensieve TMs. It allows you to use a Pensieve TM as an input or output document, just like other translatable documents such as TMX, PO, etc.","parameters":{},"processingNotes":["The filter always uses its internal encoding, so any user-specific setting for encoding is ignored."],"limitations":["Since the content of a Pensieve TM is binary, the method setOutput(OutputStream output) of the PensieveFilterWriter class is not implemented. You cannot output the content of a Pensieve TM to other types of stream without going through a format conversion."],"examples":[],"filterId":"okf_pensieve","wikiUrl":"https://okapiframework.org/wiki/index.php/pensieve_tm_filter"},"okf_phpcontent":{"filterName":"PHP Content Filter","overview":"The PHP Content Filter is an Okapi component that implements the IFilter interface for PHP content. The implementation is based on the PHP syntax found in the PHP language Reference documentation. It processes the content of PHP tags (not HTML files with embedded PHP), extracting translatable strings from constructs such as string assignments, heredoc/nowdoc syntax, and array declarations. Note that many files with a .php extension are actually HTML files with PHP tags and should not be processed with this filter.","parameters":{"useDirectives":{"description":"Enables the filter to recognize localization directives, which are special comments used to override the default extraction behavior. Localization directives have the same syntax and behavior across all Okapi filters. When this option is not set, any localization directive in the input file will be ignored and all extractable strings will be extracted regardless of directive scope.","notes":["Note: Directives override key conditions.","The syntax and behavior of the directives are the same across all Okapi filters."]},"extractOutsideDirectives":{"description":"When enabled, the filter extracts any translatable item that is not within the scope of a localization directive. Selecting to extract or not outside localization directives allows you to mark up fewer parts of the source document. This option is only enabled when 'useDirectives' is set to true.","dependsOn":[{"property":"useDirectives","condition":"must be true"}]},"useCodeFinder":{"description":"Enables pattern-based detection of inline codes within extracted text. When set, the specified regular expressions are applied to the text of extracted items, and any match is converted to an inline code placeholder. The default expressions detect: partial HTML/XML tags at the start or end of text, escape sequences (\\a, \\b, \\f, \\n, \\r, \\t, \\v), email addresses, and placeholder tokens in square or curly brackets."},"codeFinderRules":{"description":"A set of regular expression patterns used to identify inline codes (placeholders, tags, escape sequences, etc.) in translatable text. Each rule is a regex pattern; any match within the extracted text is converted to an inline code. The default rules are:\n\n1. (\\A[^<]*?>)|(<[\\w!?/].*?(>|\\Z)) — matches partial or complete HTML/XML tags\n2. (\\\\a|\\\\b|\\\\f|\\\\n|\\\\r|\\\\t|\\\\v) — matches common escape sequences\n3. (\\w[-._\\w]*\\w@\\w[-._\\w]*\\w\\.\\w{2,3}) — matches email addresses\n4. ([\\[{][\\w_$]+?[}\\]]) — matches placeholder tokens in brackets or braces\n\nRules can be added, removed, reordered, and tested interactively using the code finder editor. A sample text field allows validation of patterns, and a 'Test using all rules' option evaluates multiple rules simultaneously against the sample.","dependsOn":[{"property":"useCodeFinder","condition":"must be true"}]},"moveLeadingAndTrailingCodesToSkeleton":{"description":"When enabled, inline codes that appear at the beginning or end of a segment (segment boundaries) are moved to the skeleton (non-translatable framework), removing them from the translatable content. This can simplify the text presented to translators by keeping boundary markup out of translatable segments."},"mergeAdjacentCodes":{"description":"When enabled, consecutive inline codes that appear next to each other with no translatable text between them are merged into a single placeholder. This reduces the number of inline codes translators need to manage."},"simplifierRules":{"description":"Rules for simplifying the inline code representation in extracted text. These rules control how inline codes are presented to translators, potentially reducing complexity by combining or restructuring code placeholders according to defined patterns."}},"limitations":["Support for the define() statement is not implemented yet.","In array declarations, both the string key and string value are extracted."],"processingNotes":["Input encoding is determined by: (1) Unicode Byte-Order-Mark if present, (2) a charset declaration in the first 1000 characters of the file, or (3) the default encoding specified in filter options. If the charset value is literally 'charset' (case insensitive), the file is treated as a template with no encoding declared and the auto-detected or default encoding is used. If BOM encoding and header charset conflict, a warning is generated and the BOM encoding takes precedence.","If the file has a header entry with a charset declaration, the declaration is automatically updated in the output to reflect the selected output encoding.","For UTF-8 output: a BOM is written only if the input was also UTF-8 and had a BOM. If converting from non-UTF-8 to UTF-8, no BOM is written.","The type of line-breaks in the output matches the line-break type of the original input."],"examples":[{"title":"PHP content with various string types","description":"Demonstrates extractable text from heredoc syntax, single-quoted strings in class assignments, array values, variable assignments, and heredoc with embedded variables. The highlighted spans show what the filter extracts as translatable content.","input":"<?php\n$str = <<<EOD\nExample of string\nspanning multiple lines\nusing heredoc syntax.\nEOD;\n\nclass foo\n{\n    var $foo;\n    var $bar;\n\n    function foo()\n    {\n        $this->foo = 'Foo';\n        $this->bar = array('Bar1', 'Bar2', 'Bar3');\n    }\n}\n\n$foo = new foo();\n$name = 'MyName';\n\necho <<<EOT\nMy name is \"$name\". I am printing some $foo->foo.\nNow, I am printing some {$foo->bar[1]}.\nThis should print a capital 'A': \\x41\nEOT;\n?>","output":"Extracted translatable strings:\n1. \"Example of string\\nspanning multiple lines\\nusing heredoc syntax.\"\n2. \"Foo\"\n3. \"Bar1\", \"Bar2\", \"Bar3\"\n4. \"MyName\"\n5. \"My name is \\\"$name\\\". I am printing some $foo->foo.\\nNow, I am printing some {$foo->bar[1]}.\\nThis should print a capital 'A': \\x41\""}],"filterId":"okf_phpcontent","wikiUrl":"https://okapiframework.org/wiki/index.php/php_content_filter"},"okf_plaintext":{"filterName":"Plain Text Filter","overview":"The Plain Text Filter is an Okapi component that implements the IFilter interface for plain text documents. It processes text files encoded in ANSI, Unicode, UTF-8, and UTF-16, with automatic byte-order mark (BOM) detection. The filter supports multiple extraction modes including line-by-line, paragraph-based, spliced-line, and regex-based extraction, each available as pre-built configurations.","parameters":{"simplifierRules":{"description":"Rules for simplifying the inline code representation within extracted text units. These rules define how inline codes (placeholders, tags, and other non-translatable patterns detected by the code finder) are simplified for presentation to translators. The rules use a custom syntax specific to the Okapi simplifier engine.","dependsOn":[{"property":"useCodeFinder","condition":"must be true for inline codes to be detected and available for simplification"}]}},"limitations":["None known."],"processingNotes":["If the file has a Unicode Byte-Order-Mark (BOM), the corresponding encoding (e.g. UTF-8, UTF-16) is used automatically, overriding any default encoding specified in the filter options.","If the output encoding is UTF-8 and the input was also UTF-8, a BOM is written to the output only if one was detected in the input. If converting from a non-UTF-8 input to UTF-8 output, no BOM is added.","The type of line-breaks in the output is preserved to match the original input document."],"examples":[{"title":"Extract by lines (default)","description":"Default configuration extracts each line of text as a separate text unit. This is the simplest extraction mode for plain text files.","input":"First line of text.\nSecond line of text.\nThird line of text.","output":"Three separate text units: [First line of text.] [Second line of text.] [Third line of text.]"},{"title":"Extract by paragraphs","description":"Uses the okf_plaintext_paragraphs configuration. Paragraphs are groups of lines separated by one or more empty lines, extracted as single text units with internal line breaks handled according to the multi-line text unit settings.","input":"First line of paragraph one.\nSecond line of paragraph one.\n\nFirst line of paragraph two.","output":"Two text units: [First line of paragraph one. Second line of paragraph one.] [First line of paragraph two.]"},{"title":"Spliced lines with backslash","description":"Uses the okf_plaintext_spliced_backslash configuration. Lines ending with a backslash are merged with the following line, and inline codes are created in place of the splicer characters.","input":"This is a long \\\nline that continues.","output":"One text unit: [This is a long <x1/>line that continues.]"},{"title":"Regex extraction by lines","description":"Uses the okf_plaintext_regex_lines configuration with the rule (^(?=.+))(.*?)$ and source group 2 to extract each non-empty line as a text unit using regex-based matching.","input":"This is the first sentence. And this is the second one.\nSecond paragraph. Each one ends at the line-break.\n\nThird paragraph.\nAnd the last paragraph may have no line-break.","output":"Four text units extracted from non-empty lines, empty lines are skipped."},{"title":"Regex extraction by paragraphs","description":"Uses the okf_plaintext_regex_paragraphs configuration with the rule (\\n*)(.*?)(\\n\\n|\\Z) and source group 2, with DOTALL and MULTILINE flags, to extract blocks of text separated by double newlines as single text units.","input":"This is the first sentence. And this is the second one.\nSecond paragraph. Each one ends at the line-break.\n\nThird paragraph.\nAnd the last paragraph may have no line-break.","output":"Two text units split at the double-newline boundary."},{"title":"Trim trailing whitespace","description":"Uses the okf_plaintext_trim_trail configuration. Trailing spaces and tabs are removed from each extracted line before creating text units.","input":"Hello World   \t\nNext line  ","output":"Two text units with trailing whitespace removed: [Hello World] [Next line]"}],"filterId":"okf_plaintext","wikiUrl":"https://okapiframework.org/wiki/index.php/plain_text_filter"},"okf_po":{"filterName":"PO Filter","overview":"The PO Filter is an Okapi component that implements the IFilter interface for Gettext PO (Portable Object) resource files as well as POT (PO templates). The implementation is based on the PO specifications from the GNU gettext manual. It supports bilingual and monolingual processing modes, plural forms, domains, fuzzy flags, and various PO comment types (references, extracted comments, translator comments, and context comments).","parameters":{"protectApproved":{"description":"When enabled, all entries that are not empty and not fuzzy are set with a non-translatable flag. This effectively locks down approved translations so they are not modified during processing."},"allowEmptyOutputTarget":{"description":"When enabled, allows empty target content in the output when no translation is available. By default, if no translation exists, the output behavior depends on this flag."},"bilingualMode":{"description":"Controls whether the input document is processed as a bilingual file. In bilingual mode, the msgid entry is treated as the source text and the msgstr entry is treated as the translation — this is the normal standard way PO files are used. When disabled (monolingual mode), the msgid entry is treated as a real identifier (rather than the source text), and the corresponding translatable text is in the msgstr entry. In monolingual mode the msgid value is used as the identifier for the entry and is set as the name of the extracted resource."},"makeID":{"description":"When enabled, generates identifiers from the source text of the msgid entry. The values are constructed from the hash code of the source text, possibly with a domain prefix, and possibly with the text of the msgctxt entry. Note that the generated value may not be unique if the source text is not unique within the same domain, or has no distinct context values. The id value is set as the name of the extracted resource. This option is only effective in bilingual mode.","dependsOn":[{"property":"bilingualMode","condition":"must be true for this option to take effect"}]},"useCodeFinder":{"description":"When enabled, the specified regular expressions are applied to the text of extracted items. Any match is converted to an inline code. By default the expressions cover printf-style format specifiers (e.g. %s, %d), common escape sequences (\\n, \\r, \\t, etc.), and brace-delimited placeholders (e.g. {1})."},"codeFinderRules":{"description":"Defines the regular expression patterns used to detect inline codes (placeholders, format specifiers, escape sequences, etc.) in translatable text. The default expression is:\n\n((%(([-0+#]?)[-0+#]?)((\\d\\$)?)([\\d\\*]*(\\.[\\d\\*]*)?)[dioxXucsfeEgGpn])|((\\\\r\\\\n)|\\\\a|\\\\b|\\\\f|\\\\n|\\\\r|\\\\t|\\\\v)|(\\{\\d.*?\\}))\n\nRules can be added, removed, and reordered. Each rule is a regular expression pattern. A sample text field is available for testing the expressions. The 'useAllRulesWhenTesting' sub-option controls whether all rules are tested together or individually against the sample text.","dependsOn":[{"property":"useCodeFinder","condition":"must be true for these rules to be applied"}]},"includeMsgContextInNote":{"description":"When enabled, includes the msgctxt (message context) content in the note property of the extracted resource."},"moveLeadingAndTrailingCodesToSkeleton":{"description":"When enabled, inline codes that appear at the beginning or end of a segment are moved out of the translatable content into the skeleton (non-translatable framework). This simplifies the translatable text by removing codes that translators do not need to manage."},"mergeAdjacentCodes":{"description":"When enabled, consecutive inline codes that appear next to each other are merged into a single placeholder. This reduces clutter in the translatable content when multiple codes appear in sequence."},"simplifierRules":{"description":"Rules for simplifying the representation of inline codes in the extracted content. These rules control how inline codes are displayed or transformed to make them easier for translators to work with."},"wrapContent":{"description":"Controls whether long content lines are wrapped in the output PO file. PO files traditionally wrap long strings across multiple quoted lines."},"outputGeneric":{"description":"When enabled, produces output in a more generic format rather than the standard PO format."}},"limitations":["None known."],"processingNotes":["The filter detects input encoding in this priority order: (1) Unicode Byte-Order-Mark if present (UTF-8, UTF-16, etc.), (2) charset declaration in the PO header entry if found within the first 1000 characters of the file, (3) the default encoding specified in filter options. If the charset value is literally 'charset' (case insensitive), the file is treated as a template with no encoding declared and the auto-detected or default encoding is used.","If encoding is detected from a BOM and the header charset declaration does not match, a warning is generated and the BOM-detected encoding takes precedence.","The output charset declaration in the PO header is automatically updated to reflect the selected output encoding.","For UTF-8 output: if the input was also UTF-8, a BOM is written only if one was detected in the input; if the input was not UTF-8, no BOM is written.","No language information is updated in the PO header entry. Any language-related information needs to be updated manually in the generated PO file.","The type of line-breaks in the output matches the original input.","Plural forms are supported with the assumption that they are in sequential order (msgstr[0], msgstr[1], etc.). All msgstr strings of a plural entry are processed as a single group with type 'x-gettext-plurals'.","Domains are supported as groups with type 'x-gettext-domain' and the domain name as the group resource name.","The fuzzy flag (#, fuzzy) is mapped to the 'approved' target property: if set, approved is 'no'; if removed or changed, the fuzzy flag is removed from output.","Any quoted entry found without quotes in its first line is re-written with an initial empty string (e.g. bare 'msgid' followed by quoted continuation lines gets an empty first-line string added).","Context lines (msgctxt) are used as a differentiator for generated identifiers, so two entries with the same source text but different context will have different identifiers.","If the context is in Okapi format (e.g. 'okpCtx:tu=123'), the text unit id is set to the id provided in the context."],"examples":[{"title":"Basic PO file structure","description":"A simple PO file showing the header entry (empty msgid) with encoding and plural information, followed by a standard entry and a plural forms entry. The translatable text is in the msgid and msgid_plural lines.","input":"# PO file for myApp\n\nmsgid \"\"\nmsgstr \"\"\n\"Project-Id-Version: myApp 1.0.0\\n\"\n\"Report-Msgid-Bugs-To: \\n\"\n\"POT-Creation-Date: 2005-10-02 05:16+0200\\n\"\n\"PO-Revision-Date: 2005-03-21 11:28/-0600\\n\"\n\"Last-Translator: unknown <email@address>\\n\"\n\"Language-Team: unknown <email@address>\\n\"\n\"MIME-Version: 1.0\\n\"\n\"Content-Type: text/plain; charset=UTF-8\\n\"\n\"Content-Transfer-Encoding: 8bit\\n\"\n\"Plural-Forms: nplurals=2; plural=(n != 1);\\n\"\n\nmsgid \"diverging after version %d of %s\"\nmsgstr \"\"\n\nmsgid \"You have selected %d file for deletion\"\nmsgid_plural \"You have selected %d files for deletion\"\nmsgstr[0] \"\"\nmsgstr[1] \"\""},{"title":"Plural forms extraction to XLIFF","description":"Shows how a PO plural forms entry is extracted and represented as an XLIFF group with type 'x-gettext-plurals'. Each plural form gets a separate trans-unit with an index suffix on the resname.","input":"msgid \"untranslated-singular\"\nmsgid_plural \"untranslated-plural\"\nmsgstr[0] \"translated-singular\"\nmsgstr[1] \"translated-plural-form1\"\nmsgstr[2] \"translated-plural-form2\"","output":"<group restype=\"x-gettext-plurals\">\n  <trans-unit id=\"1\" resname=\"P3ADE34F0-0\" xml:space=\"preserve\">\n    <source xml:lang=\"en-US\">untranslated-plural</source>\n    <target xml:lang=\"fr-FR\">translated-singular</target>\n  </trans-unit>\n  <trans-unit id=\"2\" resname=\"P3ADE34F0-1\" xml:space=\"preserve\">\n    <source xml:lang=\"en-US\">untranslated-plural</source>\n    <target xml:lang=\"fr-FR\">translated-plural-form1</target>\n  </trans-unit>\n  <trans-unit id=\"3\" resname=\"P3ADE34F0-2\" xml:space=\"preserve\">\n    <source xml:lang=\"en-US\">untranslated-singular</source>\n    <target xml:lang=\"fr-FR\">translated-plural-form2</target>\n  </trans-unit>\n</group>"},{"title":"Domain support in XLIFF output","description":"Shows how PO domain directives are extracted as XLIFF groups with type 'x-gettext-domain' and the domain name as the resname.","input":"domain TheDomain1\nmsgid \"Text 1 in domain 'TheDomain1'\"\nmsgstr \"Texte 1 dans le domain 'TheDomain1'\"","output":"<group resname=\"TheDomain1\" restype=\"x-gettext-domain\">\n  <trans-unit id=\"1\" resname=\"N9D1999AB\" xml:space=\"preserve\">\n    <source xml:lang=\"en-US\">Text 1 in domain 'TheDomain1'</source>\n    <target xml:lang=\"fr-FR\">Texte 1 dans le domain 'TheDomain1'</target>\n  </trans-unit>\n</group>"},{"title":"Okapi context-based ID assignment","description":"When a msgctxt uses the Okapi format 'okpCtx:tu=<id>', the extracted text unit's ID is set to the specified value.","input":"msgctxt \"okpCtx:tu=123\"\nmsgid \"Source\"\nmsgstr \"Target\"","output":"The extracted text unit will have an id value of 123."},{"title":"Lines without quotes normalization","description":"Any entry found without quotes in its first line is automatically re-written with an initial empty string on the first line.","input":"msgid\n\"source text\"\nmsgstr\n\"target text\"","output":"msgid \"\"\n\"source text\"\nmsgstr \"\"\n\"target text\""}],"filterId":"okf_po","wikiUrl":"https://okapiframework.org/wiki/index.php/po_filter"},"okf_properties":{"filterName":"Properties Filter","overview":"The Properties Filter is an Okapi component that implements the IFilter interface for Java properties files. The implementation is based on the specification found in the Java java.util.Properties class documentation, with support for additional features for compatibility with other types of properties files. Each entry's key maps to a text unit name, the entry text maps to source content, and comments can optionally map to note properties.","parameters":{"useLd":{"description":"Enables the filter to recognize localization directives, which are special comments used to override the default extraction behavior. Localization directives have the same syntax and behavior across all Okapi filters. When this option is not set, any localization directive in the input file will be ignored.","notes":["Note: Directives have precedence over key conditions."]},"localizeOutside":{"description":"When enabled, extracts any translatable item that is not within the scope of a localization directive. Selecting to extract or not outside localization directives allows you to mark up fewer parts of the source document. This option is only enabled when 'useLd' (Use localization directives) is set.","dependsOn":[{"property":"useLd","condition":"must be true"}]},"useKeyCondition":{"description":"Enables key-based filtering of extracted items. When set, you specify a regular expression pattern in 'keyCondition'; if the key matches the pattern, the item is extracted or not depending on the 'extractOnlyMatchingKey' setting.","notes":["Note: Directives have precedence over key condition."]},"extractOnlyMatchingKey":{"description":"Controls whether the key condition pattern acts as an inclusion or exclusion filter. When true, only items with keys matching the pattern in 'keyCondition' are extracted. When false, items with keys matching the pattern are excluded from extraction.","dependsOn":[{"property":"useKeyCondition","condition":"must be true"}]},"keyCondition":{"description":"A regular expression pattern tested against the key of each entry. Used in conjunction with 'extractOnlyMatchingKey' to determine which items are extracted. The pattern must be a valid Java regular expression. For example, '.*text.*' would match any key containing 'text'.","dependsOn":[{"property":"useKeyCondition","condition":"must be true"}]},"extraComments":{"description":"When enabled, the filter recognizes additional comment styles beyond strict Java property comments (single-line starting with '#' or '!'). When set, the filter also recognizes single-line comments starting with ';', as well as single lines where '//' is the first non-whitespace sequence. Note that '//' after a '=' is considered part of the value of the entry, not a comment."},"commentsAreNotes":{"description":"When enabled, comments before each entry are included as a note property on the text unit of the corresponding entry. All comment lines before an entry are grouped into a single note."},"convertLFandTab":{"description":"When enabled, converts the escaped codes \\n and \\t in property values to true line-breaks and tab characters. All the other escaped characters remain escaped."},"escapeExtendedChars":{"description":"When enabled, converts all characters above U+007F into Unicode escape sequences (\\uHHHH) in the output. When this option is not set, only the characters not supported by the output encoding are escaped."},"idLikeResname":{"description":"When enabled, uses the keys of the extracted entries as the ID for the text units. Note that the key is already extracted into the name property (resname in XLIFF). Note also that the value of a property key may not be a valid string for some output formats; for example, in XLIFF 2 the unit ID must be an NMTOKEN value.","introducedIn":"M31"},"useJavaEscapes":{"description":"When enabled, extracted text retains Java Properties escaping conventions. When disabled (the default), escapes are resolved during extraction."},"useCodeFinder":{"description":"Enables pattern-based detection of inline codes within extracted text. When set, the specified regular expressions are applied to the text of extracted items, and any match is converted to an inline code."},"codeFinderRules":{"description":"Defines regular expression patterns used to identify inline codes (placeholders, escape sequences, format specifiers, etc.) in translatable text. The default expression matches printf-style format specifiers (e.g., %s, %d), common escape sequences (\\n, \\r, \\t, etc.), and Java MessageFormat placeholders (e.g., {0}, {1}). Each pattern is a standard Java regular expression.","dependsOn":[{"property":"useCodeFinder","condition":"must be true"}]},"mergeAdjacentCodes":{"description":"When enabled, consecutive inline codes that appear next to each other (with no translatable text between them) are merged into a single placeholder. This simplifies the segment for translators by reducing the number of inline code placeholders."},"moveLeadingAndTrailingCodesToSkeleton":{"description":"When enabled, inline codes that appear at the very beginning or end of a segment are moved out of the translatable content and into the skeleton (non-translatable framework). This reduces clutter in the translatable text by removing codes that translators should not need to reposition."},"simplifierRules":{"description":"Rules for simplifying the representation of inline codes. These rules can transform complex inline code patterns into simpler placeholder representations to make segments easier for translators to work with."}},"limitations":["None known."],"processingNotes":["If the file has a Unicode Byte-Order-Mark, the corresponding encoding (e.g., UTF-8, UTF-16) is used; otherwise the default encoding specified in the filter options is used.","For UTF-8 output: if the input was also UTF-8, a BOM is written only if one was detected in the input; if the input was not UTF-8, no BOM is written.","The type of line-breaks in the output matches the original input line-breaks.","Each property entry is mapped to a text unit: the key becomes the text unit name, the value becomes the source content, and preceding comments become notes (if the option is set)."],"examples":[{"title":"Basic properties file extraction","description":"A simple Java properties file showing which parts are extracted as translatable text. Comment lines starting with '#' are non-translatable by default. The values after '=' or ':' separators are extracted.","input":"# Example of Java properties\n\nlabelOK= OK\nmsgBadFile: Invalid input file","output":"Two text units extracted: 'OK' (key: labelOK) and 'Invalid input file' (key: msgBadFile)"},{"title":"Key condition filtering","description":"Using key condition to extract only entries whose keys match the pattern '.*text.*'. With useKeyCondition=true, extractOnlyMatchingKey=true, and keyCondition='.*text.*', only keys containing 'text' are extracted.","input":"key1 = Text for key1\ntext.err1 = Text for text.err1\nmenu_text_file = Text for menu_text_file","output":"Only 'Text for text.err1' (key: text.err1) and 'Text for menu_text_file' (key: menu_text_file) are extracted. 'key1' does not match the pattern and is skipped."},{"title":"HTML sub-filter configuration","description":"Using the sub-filter option with 'okf_html' to process property values that contain HTML markup. The HTML filter is applied to extracted content to properly handle HTML tags as inline codes.","input":"subfilter=okf_html","output":"Property values containing HTML are processed through the HTML filter, with HTML tags converted to inline codes in the text units."}],"filterId":"okf_properties","wikiUrl":"https://okapiframework.org/wiki/index.php/properties_filter"},"okf_rainbowkit":{"filterName":"Rainbow Translation Kit Filter","overview":"The Rainbow Translation Kit Filter is an Okapi component that implements the IFilter interface for any of the packages generated by the Rainbow Translation Kit Creation Step. This is a READ-ONLY filter — you cannot re-write the translation kit using this filter. It processes translation kit packages by reading their manifest file (.rkm) and the associated package contents.","parameters":{"openManifest":{"description":"Set this option to open the manifest file, and possibly modify it, before processing it. This allows you, for example, to merge back only a sub-set of the files listed in the manifest. When enabled, the manifest file is presented to the user for review or editing prior to processing. See the Rainbow Translation Kit Manifest page for details on the manifest format and editable fields.","notes":["When set to false (as in the 'okf_rainbowkit-noprompt' configuration), the manifest is processed directly without any user prompt or opportunity to modify it."]}},"limitations":["This is a READ-ONLY filter. It does not generate an output corresponding to the input and must be used for input only."],"processingNotes":["Rainbow translation kits come in different types of packages, usually corresponding to a directory with a specific layout and content.","One of the files in the directory is called manifest.rkm — this is the file to use as the input file to process the whole package."],"examples":[{"title":"Default configuration (with manifest prompt)","description":"The default configuration (okf_rainbowkit) opens the manifest file before processing, allowing the user to review or modify which files are included.","input":"Point the filter at the manifest.rkm file in the translation kit directory."},{"title":"No-prompt configuration","description":"The okf_rainbowkit-noprompt configuration sets openManifest to false, processing the manifest directly without presenting it for review. Useful for batch/automated workflows.","input":"Use configId 'okf_rainbowkit-noprompt' with openManifest=false."}],"filterId":"okf_rainbowkit","wikiUrl":"https://okapiframework.org/wiki/index.php/rainuow_translation_kit_filter"},"okf_regex":{"filterName":"Regex Filter","overview":"The Regex Filter is an Okapi component that implements the IFilter interface for any type of text-based formats where the text can be captured using regular expressions. You define rules with regular expressions that indicate what part of the document to process, and each rule is associated with an action telling the filter what to do with the different capturing groups. The filter can work with any text-based document, making it highly flexible for custom or uncommon file formats that lack a dedicated filter.","parameters":{"extractOuterStrings":{"description":"When enabled, extracts strings that appear outside the scope of the defined rules. This corresponds to the 'Extract strings outside the rules' UI option. Currently not yet implemented.","notes":["The option 'Extract strings outside the rules' is not yet implemented."]},"startString":{"description":"The character(s) specifying the start of a string. Entering several characters defines several ways to start a string. For example, setting this to '\"' means strings begin with a double-quote character. If multiple beginning characters are defined, there must be a corresponding number of end characters, where position of each end character matches the position of its corresponding beginning character.","dependsOn":[{"property":"endString","condition":"must have an equal number of characters matching startString positions"}]},"endString":{"description":"The character(s) specifying the end of a string. If multiple beginning characters are defined in startString, you must define an equal number of end characters, and the position of each end character must correspond to the position of its corresponding beginning character.","dependsOn":[{"property":"startString","condition":"must have an equal number of characters matching startString positions"}]},"useBSlashEscape":{"description":"When enabled, escaped characters use a back-slash prefix (e.g., \\\" to represent a literal double-quote inside a string). This tells the filter how to interpret escape sequences within extracted strings.","notes":["This option and useDoubleCharEscape are alternative escaping mechanisms; typically only one should be enabled."]},"useDoubleCharEscape":{"description":"When enabled, escaped characters are represented by doubling them (e.g., \"\" to represent a literal double-quote inside a string). This is an alternative to back-slash escaping.","notes":["This option and useBSlashEscape are alternative escaping mechanisms; typically only one should be enabled."]},"removeBSlashEscape":{"description":"When enabled, back-slash escape sequences are removed during processing. Controls whether escape characters are stripped from extracted content."},"oneLevelGroups":{"description":"When enabled, sections defined with 'Start a section' actions automatically close the previous section when a new one starts, limiting group nesting to a single level. If this option is set, you must not define a corresponding 'End a section' rule. If this option is not set, each 'Start a section' action must have a corresponding 'End a section' action."},"useLd":{"description":"When enabled, the filter recognizes localization directives present in the input document. If this option is not set, any localization directive in the input file will be ignored. Localization directives allow fine-grained control over what content is extracted.","notes":["When disabled, all localization directives in the input file are ignored."]},"localizeOutside":{"description":"When enabled, any translatable item that is not within the scope of a localization directive will be extracted. This allows you to mark up fewer parts of the source document by controlling whether content outside directive scope is extracted or skipped.","dependsOn":[{"property":"useLd","condition":"must be true for this option to have effect"}]},"regexOptions":{"description":"An integer bitmask controlling the regular expression options applied to all rules. The value is a combination of Java Pattern flags: DOTALL (32) makes dot match line-feeds, MULTILINE (8) makes ^ and $ match at line terminators, and CASE_INSENSITIVE (2) ignores letter case differences. Common values: 40 (DOTALL + MULTILINE), 8 (MULTILINE only). Individual rules can override these options using the (?idmsux-idmsux) construct within their pattern.","notes":["These options apply globally to all rules. Use the (?idmsux-idmsux) construct in individual rule patterns to override for specific rules.","DOTALL (32): Dot also matches line-feed. MULTILINE (8): ^ and $ match at line terminators. CASE_INSENSITIVE (2): Ignore case differences."]},"mimeType":{"description":"The MIME type value to use when extracting content with these parameters. The value is used to identify the type of document and may also change the way text is written back into the original format. Most of the time 'text/plain' should be fine.","notes":["Most of the time 'text/plain' should be fine."]},"subFilter":{"description":"Specifies a sub-filter to apply to extracted content. When set, the extracted text units are further processed by the specified filter, enabling nested content handling."},"moveLeadingAndTrailingCodesToSkeleton":{"description":"When enabled, inline codes that appear at the beginning or end of a segment are moved to the skeleton (non-translatable portion), keeping the translatable content cleaner for translators."},"mergeAdjacentCodes":{"description":"When enabled, consecutive inline codes are merged into a single placeholder, simplifying the inline code representation for translators."},"simplifierRules":{"description":"Rules for simplifying inline code representation. These rules define how complex inline code patterns should be condensed or simplified for presentation to translators."}},"limitations":["The whole document is loaded in memory to apply the regular expressions. This may cause issues with very large documents.","The option 'Extract strings outside the rules' (extractOuterStrings) is not yet implemented."],"processingNotes":["Input encoding is determined by Unicode Byte-Order-Mark if present; otherwise the default encoding specified when opening the document is used.","The filter does not recognize any encoding declarations in the document and therefore cannot update them.","If the output encoding is UTF-8 and the input was also UTF-8, a BOM is used only if one was detected in the input. If the input was not UTF-8, no BOM is used in the output.","Line-break type in the output matches the original input.","Parsing proceeds sequentially: the filter searches from the current position for the first matching rule, applies the associated action, advances the position to the end of the match, and repeats until no more matches are found or the end of the document is reached.","Rules are evaluated in list order; the first rule that matches at the current position is applied."],"examples":[{"title":"Basic key=value extraction","description":"Demonstrates extracting translatable text from a simple key=value format using a regex rule with the 'Extract the content' action. The regex '^\\[(.*?)\\](=|:)(.*?)$' captures the key name (group 1) as the identifier and the text (group 3) as the source content.","input":"[ID1]=Text for ID1\n[ID2]:Text for ID2","output":"<trans-unit id=\"1\" resname=\"ID1\" xml:space=\"preserve\">\n  <source xml:lang=\"en\">Text for ID1</source>\n</trans-unit>\n<trans-unit id=\"2\" resname=\"ID2\" xml:space=\"preserve\">\n  <source xml:lang=\"en\">Text for ID2</source>\n</trans-unit>"},{"title":"SRT subtitle extraction","description":"Configuration for SRT (Sub-Rip Text) subtitle files using DOTALL+MULTILINE regex options (regexOptions=40). The rule pattern '^(\\d+:\\d+:\\d+.*?)\\n(.*?)(\\n\\n+|\\z)' captures timestamp info as a note (group 1) and subtitle text as source (group 2), with blocks separated by double line-breaks. preserveWS is true and inline code finder detects HTML tags.","input":"1\n00:00:06,020 --> 00:00:07,020\nHi, everyone.\nthis is more\n\n2\n00:00:07,020 --> 00:00:08,020\nMy name is Randy Becker.","output":"Text units extracted with subtitle text as source and timestamp ranges as notes."},{"title":"Metadata rules (FPRM-only)","description":"Metadata rules are defined only in the FPRM parameters file (not accessible in the UI). The rule name and matched regex content is added as metadata to the TextUnit. Useful for capturing auxiliary information like timestamps.","input":"metaRuleCount.i=2\nmetaRule0.ruleName=meta1\nmetaRule0.expr=(\\d\\d:\\d\\d:\\d\\d)\nmetaRule1.ruleName=meta2\nmetaRule1.expr=(\\d\\d:\\d\\d:\\d\\d)","output":"Matched content is added as metadata properties on the TextUnit, keyed by ruleName."},{"title":"Macintosh .strings file extraction","description":"Configuration for Mac .strings files using 6 rules in priority order: (1) comments followed by quoted key=value, (2) comments followed by unquoted key=value, (3) bracketing comments for localization directives, (4) line comments, (5) standalone quoted key=value, (6) standalone unquoted key=value. Inline code finder rules detect printf-style format specifiers (%d, %@, etc.), escape sequences (\\n, \\t, etc.), and HTML tags.","input":"/* Menu item to make the current document plain text */\n\"Make Plain Text\" = \"Make Plain \\\"Text\";\n/* Menu item to make the current document rich text */\n\"Make Rich Text\" = \"Make Rich Text\";","output":"Two text units extracted: source='Make Plain \"Text' with name='Make Plain Text' and note='Menu item to make the current document plain text'; source='Make Rich Text' with name='Make Rich Text' and note='Menu item to make the current document rich text'."}],"filterId":"okf_regex","wikiUrl":"https://okapiframework.org/wiki/index.php/regex_filter"},"okf_sdlpackage":{"filterName":"SDL Trados Package Filter","overview":"The SDL Trados Package Filter is an Okapi component that implements the IFilter interface for SDL Trados SDLPPX and SDLRPX files. It is an extension of the Archive Filter that reads the input package, detects the SDLXLIFF files for the specified language pair, and uses the XLIFF Filter (with the okf_xliff-sdl configuration) to process the content. Each SDLXLIFF file inside the package corresponds to a sub-document in the Okapi filter events. The filter is implemented in the class net.sf.okapi.filters.sdlpackage.SdlPackageFilter.","parameters":{"mimeType":{"description":"MIME type of the filter's container format. Defaults to 'application/x-archive'. This is inherited from the Archive Filter base and identifies the container format being processed."},"fileNames":{"description":"Comma-delimited list of file names to be processed within the archive package. Wildcards are allowed (e.g., '*.tmx,*.xlf,*.xlff'). The file names must be listed in the same order as the corresponding configuration IDs in the configIds parameter. The filter uses these patterns to detect which files inside the SDLPPX/SDLRPX package should be extracted and processed.","dependsOn":[{"property":"configIds","condition":"must have a matching configuration ID for each file name pattern, in the same order"}]},"configIds":{"description":"Comma-delimited list of Okapi filter configuration IDs corresponding to the file name patterns specified in fileNames. Each configuration ID determines which Okapi filter is used to process matching files. For SDL Trados packages, the SDLXLIFF files are processed using the XLIFF Filter with the 'okf_xliff-sdl' configuration. Default value is 'okf_tmx,okf_xliff,okf_xliff'.","dependsOn":[{"property":"fileNames","condition":"must have a matching file name pattern for each configuration ID, in the same order"}]},"moveLeadingAndTrailingCodesToSkeleton":{"description":"When enabled, inline codes (tags, placeholders) that appear at the beginning or end of a segment are moved out of the translatable content and into the skeleton (non-translatable portion). This simplifies the text units presented to translation tools by removing boundary codes that do not need to be repositioned by translators."},"mergeAdjacentCodes":{"description":"When enabled, consecutive inline codes that appear next to each other are merged into a single placeholder. This reduces the number of individual inline codes in the translatable content, making segments simpler and easier to work with in translation tools."},"simplifierRules":{"description":"Rules for simplifying the inline code representation in extracted text units. These rules define how complex inline code sequences can be reduced to simpler representations, making the content easier for translators to process."}},"limitations":["Reading an SDLPPX file and writing it back produces another SDLPPX file, not an SDLRPX file.","All limitations of the XLIFF Filter also apply to this filter, since SDLXLIFF content is processed using the XLIFF Filter with the okf_xliff-sdl configuration."],"processingNotes":["This filter is an extension of the Archive Filter and inherits its processing behavior for container formats.","The filter detects SDLXLIFF files for the specified language pair within the package.","The XLIFF Filter with the okf_xliff-sdl configuration is used to process SDLXLIFF content inside the package.","Each SDLXLIFF file inside the package corresponds to a sub-document in the Okapi filter events."],"examples":[],"filterId":"okf_sdlpackage","wikiUrl":"https://okapiframework.org/wiki/index.php/sdl_trados_package_filter"},"okf_simplification":{"filterName":"Simplification Filter","overview":"The Simplification Filter is a wrapper around another (internal) filter, used to transform events generated by that internal filter through resource simplification. It internally employs the Resource Simplifier Step and the Inline Codes Simplifier Step, either or both of which can be activated through filter parameters. The default internal filter configuration is okf_xmlstream (XML Stream Filter), but any registered Okapi filter configuration can be used.","parameters":{"filterConfigId":{"description":"The configuration ID for the internal filter. The internal filter is instantiated automatically and generates events that are then simplified based on the simplifyResources and simplifyCodes parameters. The default value is 'okf_xmlstream', which uses the XML Stream Filter. You can use any filter configuration for any filter registered with Okapi.","notes":["The internal filter is instantiated automatically based on this configuration ID."]},"simplifyResources":{"description":"When enabled, simplifies resources generated by the internal filter by removing references from resources (resource flattening). This activates the Resource Simplifier Step internally.","notes":["At least one of simplifyResources or simplifyCodes must be active, otherwise the filter generates an error."]},"simplifyCodes":{"description":"When enabled, merges adjacent inline codes in the source part of a text unit, and moves leading and trailing codes of the source to the skeleton. This activates the Inline Codes Simplifier Step internally.","notes":["At least one of simplifyResources or simplifyCodes must be active, otherwise the filter generates an error."]}},"limitations":["This filter is BETA."],"processingNotes":["The filter internally creates and employs two steps: Resource Simplifier Step and Inline Codes Simplifier Step.","The default configuration for the internal filter is okf_xmlstream (XML Stream Filter), but any filter configuration registered with Okapi can be used.","At least one of the simplify options (simplifyResources or simplifyCodes) must be active, otherwise the filter generates an error."],"examples":[],"filterId":"okf_simplification","wikiUrl":"https://okapiframework.org/wiki/index.php/simplification_filter"},"okf_table":{"filterName":"Table Filter","overview":"The Table Filter is an Okapi component that implements the IFilter interface for plain text table documents. It supports multiple table formats including CSV (comma/character-separated), TSV (tab-separated), and fixed-width columns. The filter can extract translatable text from specific columns, handle headers with column names, and manage multi-line text units. It is implemented in the class net.sf.okapi.filters.table.TableFilter.","parameters":{"simplifierRules":{"description":"Rules for simplifying inline code representation. These rules control how inline codes detected in extracted text are simplified or transformed before being presented in text units."}},"limitations":["None known."],"processingNotes":["Input encoding is determined by Unicode Byte-Order-Mark if present; otherwise the default encoding specified in filter options is used.","For UTF-8 output: if input was also UTF-8, a BOM is written only if one was detected in the input; if input was not UTF-8, no BOM is written to the output.","The type of line-breaks in the output is preserved from the original input."],"examples":[{"title":"CSV with header row","description":"A typical CSV file where the first line contains column names and data starts from line 2. Set valuesStartLineNum=2 and columnNamesLineNum=1.","input":"Name,Description,Translation\nHello,Greeting,Hola\nGoodbye,Farewell,Adiós","output":"Text units extracted from each cell in the data rows (lines 2+), with column names optionally extracted based on sendHeaderMode."},{"title":"Text qualifier escaping with duplicate qualifier","description":"When a field contains the active text qualifier (quotation mark), escaping is done by duplicating the qualifier character. The escapingMode is set to 0 (duplicate qualifier).","input":"\"Text, \"\"quoted text\"\"\"","output":"Extracted text: Text, \"quoted text\""},{"title":"Text qualifier escaping with backslash","description":"When a field contains the active text qualifier, escaping is done by prefixing with a backslash character. The escapingMode is set to 1 (backslash).","input":"\"Text, \\\"quoted text\\\"\"","output":"Extracted text: Text, \"quoted text\""},{"title":"Trimming modes for qualified vs non-qualified fields","description":"When trimMode is set to 'Only entries without qualifiers' (value 1), only non-qualified field values are trimmed. With trimMode 'All' (value 2), both qualified and non-qualified values are trimmed.","input":"\"  text \",  non-qualified  ","output":"With trimMode=1: [  text ] and [non-qualified]. With trimMode=2: [text] and [non-qualified]."}],"filterId":"okf_table","wikiUrl":"https://okapiframework.org/wiki/index.php/taule_filter"},"okf_tmx":{"filterName":"TMX Filter","overview":"The TMX Filter is an Okapi component that implements the IFilter interface for TMX (Translation Memory eXchange) documents. TMX is a LISA Standard that defines a file format for transporting translation memory data from one translation tool to another. The filter is implemented in the class net.sf.okapi.filters.tmx.TmxFilter and supports the TMX 1.4b specification.","parameters":{"segType":{"description":"Controls whether a segment is created for each extracted <tu> entry, and under what conditions based on the segtype attribute. The following integer values correspond to the available options: 'Always creates the segment' (creates the segment regardless of the segtype attribute value), 'Never creates the segment' (never creates the segment, even if segtype is set to \"sentence\"), 'Creates the segment if segtype is \"sentence\" or is undefined' (creates the segment when segtype is \"sentence\" or not defined), and 'Creates the segment only if segtype is \"sentence\"' (only creates the segment if segtype is explicitly set to \"sentence\"). Default is 2."},"processAllTargets":{"description":"When enabled, all target <tuv> elements are read into the text unit. When disabled, only the selected target is read and all remaining target <tuv> elements become part of the skeleton. Default is true. Any effect this setting has depends on the following pipeline steps and the ability they have to process multiple targets."},"consolidateDpSkeleton":{"description":"When enabled, consolidates the skeleton parts from document parts and sends fewer events through the pipeline. Default is true. This is sufficient in most cases, but as a pipeline developer you might sometimes want to have access to more fine-grained resources in the pipeline, in which case this should be disabled."},"exitOnInvalid":{"description":"Controls behavior when invalid <tu> elements are encountered. By default (false), invalid <tu>s are skipped along with warning message(s). Enable this option to be notified immediately of invalid content so you can correct the file before re-running it.","notes":["By using the default setting (skip invalid <tu>s) or ignoring the warning messages, you might run the risk of getting a processed file that doesn't match the input file."]},"propValueSep":{"description":"The string used to separate duplicate property values when there are duplicate properties in a TU. Default is \", \" (comma followed by a space)."},"moveLeadingAndTrailingCodesToSkeleton":{"description":"Move inline codes at segment boundaries to the skeleton (non-translatable)."},"mergeAdjacentCodes":{"description":"Merge consecutive inline codes into a single placeholder."},"simplifierRules":{"description":"Rules for simplifying inline code representation."},"escapeGT":{"description":"When enabled, all greater-than characters ('>') are escaped as '&gt;' in the output. Default is false."}},"limitations":["The <sub> element is not supported. When such element is found, a warning is issued, and the element content is put with the content of its parent element.","The filter is not able to reconstruct any DTD declaration."],"processingNotes":["If the document has an encoding declaration it is used; otherwise UTF-8 is used as the default encoding regardless of any default encoding specified when opening the document.","For UTF-8 output: if the input encoding was also UTF-8, a Byte-Order-Mark is used only if one was detected in the input document; if the input encoding was not UTF-8, no BOM is used.","The type of line-breaks of the output is the same as the one of the original input."],"examples":[],"filterId":"okf_tmx","wikiUrl":"https://okapiframework.org/wiki/index.php/tmx_filter"},"okf_tradosrtf":{"filterName":"Trados-Tagged RTF Filter","overview":"The Trados-Tagged RTF Filter is an Okapi component that implements the IFilter interface for RTF files prepared with the Trados translation layer of styles. It reads Trados-Tagged RTF documents — RTF files with special styles (such as tw4wInternal and tw4wExternal) associated to different parts of the content, along with segmentation markers. This is a read-only filter; it cannot merge back extracted data. Note that \"normal\" RTF files translated with Trados (where formatting is true RTF codes rather than tagged text with Trados styles) are not supported.","parameters":{},"limitations":["This is a READ-ONLY filter. It does not generate an output corresponding to the input and must be used for input only.","The filter only understands inline codes represented with Trados styles (tw4wInternal, tw4wExternal), not RTF with \"normal\" formatting."],"processingNotes":["The document has encoding information defined for each font. The default encoding is normally declared in the document.","If there is no default encoding declared in the document, the encoding specified by the user is used as the default.","Only text marked by Trados segmentation markers is taken into account. Any text outside the segment markers is ignored and considered non-translatable."],"examples":[],"filterId":"okf_tradosrtf","wikiUrl":"https://okapiframework.org/wiki/index.php/trados_tagged_rtf_filter"},"okf_transifex":{"filterName":"Transifex Filter","overview":"The Transifex Filter is an Okapi component that implements the IFilter interface to process online Transifex projects. Transifex is an open-source translation collaborative platform where one party can upload files for translation and another party can access these files to translate them online or locally. The filter takes a local Transifex project file (.txp) as input, connects to the Transifex host using stored credentials, and processes PO resources from the project, sending standard filter events.","parameters":{"openProject":{"description":"When enabled, the project file (.txp) is opened in an editor dialog before processing begins, allowing the user to view and modify project settings and select which resources to process. When disabled, the filter processes the project file directly without presenting the editor dialog. This is useful for batch/automated processing where no user interaction is desired.","notes":["The 'okf_transifex-noPrompt' configuration sets this to false for automated processing without user interaction."]},"moveLeadingAndTrailingCodesToSkeleton":{"description":"When enabled, inline codes (such as formatting tags or placeholders) that appear at the very beginning or end of a segment are moved out of the translatable text and into the skeleton (non-translatable portion). This simplifies segments for translators by removing codes that surround but are not embedded within the translatable content."},"mergeAdjacentCodes":{"description":"When enabled, consecutive inline codes that appear next to each other with no translatable text between them are merged into a single placeholder code. This reduces clutter in the translatable text by consolidating adjacent codes into one unit."},"simplifierRules":{"description":"Rules for simplifying the representation of inline codes in the extracted text. These rules define how complex inline code patterns should be reduced to simpler placeholder representations, making the text easier for translators to work with."}},"limitations":["This filter is BETA.","Transifex loses fuzzy flags and the corresponding translations when downloading a PO file that was uploaded with fuzzy entries. The only way to do round-trips without losing target text is to not label it as fuzzy, which often results in resources marked as 100% translated after upload even when translations may not be final.","Only PO-based files in Transifex are handled, not TS files.","Due to limitations in the pipeline mechanism, this filter cannot be used with steps that re-write different output corresponding to the resource, other than the Filter Events to Raw Document Step. For example, it will not work properly with the Rainbow Translation Kit Creation Step."],"processingNotes":["The filter takes a local Transifex project file (.txp) as input, which is a UTF-8 text file containing host URL, credentials, project ID, locale settings, and resource selections.","If the .txp file contains no resources, the filter connects to the Transifex host using the specified credentials and fetches the list of all resources for the project. If resources are already listed, it uses the existing list without refreshing.","For each PO resource whose source language matches the specified source locale, the filter downloads the translation file for the target language. If no translation file exists yet, an empty-translation file is created instead.","The downloaded PO file is opened and processed, sending the usual filter events as received from a PO file. When one resource is done, it moves to the next.","When the filter-writer is used (e.g., in the Filter Events to Raw Document Step), modified PO files are re-created and pushed back into the Transifex project using the same credentials.","Source and target locale values in the .txp file are used only as fall-back values; in most situations the locales are driven by the application calling the filter."],"examples":[{"title":"Transifex project file (.txp) format","description":"Example of a .txp project file showing the format with host, credentials, project settings, and resource selection. Lines starting with # are comments. Resources can be selected (yes) or deselected (no) with a tab-separated flag.","input":"host=http://www.transifex.net\nuser=johndoe\npassword=xrt34@asf\nprojectId=myproject\nprotectApproved=yes\n# Fall-back values for the source and target locales:\nsourceLocale=en\nsourceLocale=fr\n# Resources\nmyfile1xmlpo\tyes\nmyfile2odtpo\tno"}],"filterId":"okf_transifex","wikiUrl":"https://okapiframework.org/wiki/index.php/transifex_filter"},"okf_ts":{"filterName":"TS Filter","overview":"The TS Filter is an Okapi component that implements the IFilter interface for Qt TS (Translation Source) resource files. It is implemented in the class net.sf.okapi.filters.ts.TsFilter. The implementation is based on the TS specification found at the Qt/Trolltech documentation for the linguist TS file format. The filter handles extraction and merging of translatable content from TS files, including translation status mapping and translator comments.","parameters":{"escapeGT":{"description":"Controls whether the greater-than character (>) is escaped as &gt; in the output. When set to false (the default), > characters are written as-is."},"decodeByteValues":{"description":"When enabled, converts all <byte value=\"[value]\"/> elements in the TS document to raw characters. When disabled, these elements are not converted and are instead treated as inline codes. Note that these characters are stored as special <byte/> elements in TS because they are invalid in XML.","notes":["Note: Those characters are stored as special elements in TS because they are invalid in XML, so it may be better to keep them as inline codes if you are working with other XML-based formats like XLIFF or TMX."]},"useCodeFinder":{"description":"Set this option to use the specified regular expressions on the text of the extracted items. Any match will be converted to an inline code. When enabled, the patterns defined in codeFinderRules are applied to detect inline codes in translatable text.","dependsOn":[{"property":"codeFinderRules","condition":"codeFinderRules defines the patterns used when useCodeFinder is enabled"}]},"codeFinderRules":{"description":"Defines the regular expression patterns used to identify inline codes in translatable text. Each rule specifies a regex pattern; any text matching a rule is converted to an inline code. Rules can be added, removed, and reordered. The interface provides test data validation to preview which text segments will be matched. By default, the TS filter includes patterns for: printf-style format specifiers (e.g., %d, %s, %1$s), escape sequences (\\r\\n, \\a, \\b, \\f, \\n, \\r, \\t, \\v), and curly-brace placeholders (e.g., {0}, {1}).","dependsOn":[{"property":"useCodeFinder","condition":"must be true for these rules to be applied"}],"notes":["Expressions must be valid regular expressions. Automatic syntax checking is performed against provided test data to show real-time effects.","The 'Test using all rules' option allows simultaneous testing across multiple expressions rather than individual rule evaluation."]},"moveLeadingAndTrailingCodesToSkeleton":{"description":"When enabled, inline codes that appear at the beginning or end of a segment are moved out of the translatable content and into the skeleton (non-translatable portion). This can simplify the text presented to translators by removing leading/trailing placeholders or tags from translatable segments."},"mergeAdjacentCodes":{"description":"When enabled, consecutive inline codes that appear next to each other (with no translatable text between them) are merged into a single placeholder. This reduces the number of individual inline codes translators need to manage."},"simplifierRules":{"description":"Rules for simplifying the representation of inline codes. These rules control how inline codes are displayed or simplified for translator-facing formats, potentially reducing complexity in the presented content."}},"limitations":["There are sometimes issues with extracting and merging back <numerusform> elements. A round-trip test should be performed before sending for translation."],"processingNotes":["Line-breaks in the output preserve the same type as the original input (no line-break normalization).","The <translation> element's 'type' attribute is mapped to the target 'approved' property: no type attribute means approved='yes', type='unfinished' means approved='no', and type='obsolete' causes the entry to not be extracted at all (these are unused entries per Qt documentation).","The filter stores <translatorcomment> elements as text unit Property.TRANSNOTE, which can be used by subsequent pipeline steps or editors."],"examples":[{"title":"Default inline code patterns","description":"The default regular expression patterns configured for inline code detection in TS files. These patterns match printf-style format specifiers, escape sequences, and curly-brace placeholders.","input":"((%(([-0+#]?)[-0+#]?)((\u0005\\d\\$)?)(([\u0005\\d\\*]*)(\u0005\\.[\u0005\\d\\*]*)?)[dioxXucsfeEgGpn])\n|((\\\\r\\\\n)|\\\\a|\\\\b|\\\\f|\\\\n|\\\\r|\\\\t|\\\\v)\n|(\\{\\d.*?\\}))"},{"title":"Translation type attribute mapping","description":"Shows how the 'type' attribute on the <translation> element maps to the extracted entry's approved state.","input":"<message>\n  <source>Hello</source>\n  <translation type=\"unfinished\">Bonjour</translation>\n</message>","output":"Entry extracted with target property approved='no' because type='unfinished'"},{"title":"Obsolete entries are skipped","description":"Entries with type='obsolete' on the translation element are not extracted at all, as they represent unused entries.","input":"<message>\n  <source>Old text</source>\n  <translation type=\"obsolete\">Ancien texte</translation>\n</message>","output":"Entry is NOT extracted (skipped entirely)"}],"filterId":"okf_ts","wikiUrl":"https://okapiframework.org/wiki/index.php/ts_filter"},"okf_ttx":{"filterName":"TTX Filter","overview":"The TTX Filter is an Okapi component that implements the IFilter interface for Trados TTX documents. TTX is an XML-based bilingual format used by some versions of the Trados tools and supported by several other tools. There are no official public specifications available for the format. The filter handles segmentation, existing translations with match percentages, and supports various extraction modes.","parameters":{"segmentMode":{"description":"Selects the type of extraction to perform based on possible existing segments. Value 0 (Auto-detect existing segments): If at least one segment is detected in the file, only existing segments are extracted; if no segment is detected, all text is extracted. Value 1 (Extract only existing segments): Only existing segments are extracted; if the file is not pre-segmented, no text is extracted. Value 2 (Extract all): Extract all text, whether it is in existing segments or not. In auto-detection mode (0), the filter tries to detect if the file has at least one existing segment and then behaves as mode 1 or mode 2 accordingly.","notes":["Segmentation is often a cause for interoperability issues. For a better compatibility with the tool that created the TTX files it is recommended to work with pre-segmented documents."]},"moveLeadingAndTrailingCodesToSkeleton":{"description":"When enabled, inline codes that appear at the beginning or end of a segment are moved to the skeleton (non-translatable portion), removing them from the translatable content. This can simplify the text units presented to translators by removing boundary codes that are not relevant for translation."},"mergeAdjacentCodes":{"description":"When enabled, consecutive inline codes that appear next to each other are merged into a single placeholder. This reduces the number of inline codes translators need to manage and simplifies the translatable content."},"simplifierRules":{"description":"Rules for simplifying the inline code representation in extracted text. These rules define how complex inline codes (tags, placeholders, etc.) are simplified into more manageable representations for translation tools. The rules are edited using the simplifier rules editor."},"escapeGT":{"description":"When enabled, all greater-than characters ('>') are escaped as '&gt;' in the output. By default this option is off, meaning greater-than characters are written as-is in the output."}},"limitations":["The TTX element <df> may cause problems in some cases, for example when spanning across an external tag (e.g., when bold formatting spans across paragraph boundaries which are external tags in TTX)."],"processingNotes":["If the document has an encoding declaration it is used; otherwise UTF-8 is used as the default encoding regardless of the actual default encoding specified when opening the document.","For UTF-8 output: if the input was also UTF-8, a BOM is used only if one was detected in the input; if the input was not UTF-8, no BOM is used in the output.","The type of line-breaks in the output is preserved from the original input.","TTX is a format where the target text cannot be represented if the text is not segmented; the output includes any new <Tu> and <Tuv> elements needed.","Segmented entries may have existing translations. If MatchPercent > 100 and Origin is 'xtranslate', the match type is set to EXACT_LOCAL_CONTEXT (corresponding to XU matches in TagEditor). If MatchPercent > 99, match type is EXACT. If MatchPercent is between 1 and 100 (exclusive), match type is FUZZY. The Origin attribute value is carried over to the annotation if present."],"examples":[{"title":"Extract All mode (mode 2) — mixed segmented and unsegmented content","description":"In mode 2 (Extract all), both segmented and unsegmented text parts are extracted. The entire Raw element content becomes a single text unit with three segments.","input":"...<Raw>\nPart 1 <Tu MatchPercent=\"0\">\n<Tuv Lang=\"EN\">Part 2</Tuv></Tu> Part 3.\n</Raw>...","output":"[Part 1 ][Part 2][ Part 3]"},{"title":"Extract Existing Segments Only mode (mode 1) — same content","description":"In mode 1 (Extract only existing segments), only the text within existing <Tu>/<Tuv> segments is extracted. Unsegmented text parts are skipped.","input":"...<Raw>\nPart 1 <Tu MatchPercent=\"0\">\n<Tuv Lang=\"EN\">Part 2</Tuv></Tu> Part 3.\n</Raw>...","output":"[Part 2]"}],"filterId":"okf_ttx","wikiUrl":"https://okapiframework.org/wiki/index.php/ttx_filter"},"okf_txml":{"filterName":"TXML Filter","overview":"The TXML Filter is an Okapi component that implements the IFilter interface for Wordfast Pro TXML documents. TXML is a proprietary XML-based bilingual format used by Wordfast Pro and supported by several other tools. There are no official public specifications available.","parameters":{"allowEmptyOutputTarget":{"description":"Controls whether empty translations are written out as-is in the output. When set to true (the default), empty target segments are allowed in the output document. When set to false, a copy of the source text is used in place of any empty translation, ensuring that every segment in the output has content."},"moveLeadingAndTrailingCodesToSkeleton":{"description":"When enabled, inline codes that appear at the beginning or end of a segment are moved out of the translatable content and into the skeleton (non-translatable portion). This simplifies the text presented to translators by removing boundary codes that do not need translation."},"mergeAdjacentCodes":{"description":"When enabled, consecutive inline codes that appear next to each other are merged into a single placeholder. This reduces the number of inline codes translators need to manage when adjacent codes can be treated as a single unit."},"simplifierRules":{"description":"Defines rules for simplifying the inline code representation in extracted content. These rules control how complex inline markup is reduced to simpler placeholder representations for translation. The rules follow the Okapi simplifier rules syntax."}},"limitations":["The TXML format does not allow different source and target content for the parts between segments; if any of those inter-segment parts change after extraction, the difference cannot be represented when merging — only the source representation is preserved."],"processingNotes":["If the document has an encoding declaration it is used; otherwise UTF-8 is used as the default encoding, regardless of any default encoding specified when opening the document.","For UTF-8 output: a BOM is included only if the input was also UTF-8 and had a BOM. If the input was not UTF-8, no BOM is added.","If the original document had an XML encoding declaration it is updated; if it did not have one, a declaration is automatically added.","The type of line-breaks in the output matches the original input.","TXML files are organized into blocks of one or more segments. Each block is extracted as a single text unit with as many segments as there are in the block.","Segmented entries may have translations; the target text is extracted along with the source. If a segment has gtmt=\"true\" and not modified=\"true\", source and target are also set as an AltTranslationsAnnotation.","Only the latest translation revision is extracted; translations in <revisions> elements are ignored. The filter does not create revision entries — updated translations overwrite the original with no revision history preserved."],"examples":[],"filterId":"okf_txml","wikiUrl":"https://okapiframework.org/wiki/index.php/txml_filter"},"okf_vignette":{"filterName":"Vignette Filter","overview":"The Vignette Filter is an Okapi component that implements the IFilter interface for export/import XML documents used with the Vignette Content Management System. The Vignette XML documents are the files generated by the vgnexport tool of Vignette. It supports bilingual and monolingual modes, extracting translatable content from named attribute elements within the export files.","parameters":{"partsNames":{"description":"Comma-separated list of the values for the name attribute of the <attribute> elements to extract. Each entry corresponds to a named content part in the Vignette export XML. For example, if the content body is stored in the 'MYVCM-BODY' entry, it appears in the XML as <attribute name=\"MYVCM-BODY\"><valueCLOB>data</valueCLOB></attribute>. The list must have the same number of entries as the partsConfigurations list, and entries must be in the same order."},"partsConfigurations":{"description":"Comma-separated list of the filter configurations to use for each extractable part. This list must contain the same number of entries as the partsNames list, and be in the same order. Use 'default' to indicate no specific filter configuration for that part. Other values should be valid Okapi filter configuration IDs (e.g., 'okf_html').","dependsOn":[{"property":"partsNames","condition":"must have the same number of comma-separated entries, in the same order"}]},"monolingual":{"description":"Set this option to process monolingual documents, where all importContentInstance elements are to be extracted. When this option is set, the filter does not use the sourceId and localeId parameters. In non-monolingual (bilingual) mode, the filter requires both source and target importContentInstance elements with matching source IDs."},"sourceId":{"description":"The value for the name attribute of the <attribute> element that contains the source ID for a given block. This is used to establish the relationship between source and target importContentInstance blocks — both blocks must share the same source ID value. Not used when monolingual mode is enabled.","dependsOn":[{"property":"monolingual","condition":"must be false (disabled when monolingual mode is true)"}]},"localeId":{"description":"The value for the name attribute of the <attribute> element that contains the locale ID for a given block. Not used when monolingual mode is enabled.","dependsOn":[{"property":"monolingual","condition":"must be false (disabled when monolingual mode is true)"}]},"useCDATA":{"description":"When enabled, creates CDATA sections in the output file. When disabled, the content is written as escaped HTML instead of being wrapped in CDATA sections."},"quoteModeDefined":{"description":"Boolean flag indicating whether the quoteMode parameter has been explicitly defined. When false, the default quoting behavior is used."},"quoteMode":{"description":"Controls the quoting mode for the output. Only takes effect when quoteModeDefined is true.","dependsOn":[{"property":"quoteModeDefined","condition":"must be true for quoteMode to take effect"}]},"moveLeadingAndTrailingCodesToSkeleton":{"description":"When enabled, inline codes (such as HTML tags) that appear at the beginning or end of a segment are moved to the skeleton (non-translatable framework), removing them from the translatable text. This simplifies the translatable content by keeping boundary codes out of segments."},"mergeAdjacentCodes":{"description":"When enabled, consecutive inline codes that appear next to each other are merged into a single placeholder. This reduces the number of inline codes translators need to handle."},"simplifierRules":{"description":"Rules for simplifying the inline code representation in translatable content. These rules define how complex inline code sequences should be simplified for translator-facing output."}},"limitations":["Very large documents may cause memory problems."],"processingNotes":["Input and output encodings are forced to UTF-8.","In bilingual mode, you must have an importContentInstance element for both the source and the target language in the export file to be able to extract data. Entries that have only an importContentInstance for the source will not be extracted but will be listed as a warning. Entries that have no importContentInstance for the source will not be extracted and will be listed as a warning.","The relationship between source and target importContentInstance blocks is established using the source ID defined in the parameters — both blocks must have the same source ID value.","These constraints do not apply when Monolingual mode is used."],"examples":[{"title":"Vignette XML attribute structure","description":"Shows how a named content entry (e.g., MYVCM-BODY) appears in a Vignette export XML document. Each extractable part is stored as an <attribute> element with a name attribute, containing a <valueCLOB> child with the actual data.","input":"<attribute name=\"MYVCM-BODY\">\n<valueCLOB>data</valueCLOB>\n</attribute>"},{"title":"Default configuration (with CDATA)","description":"The default configuration extracts standard Vignette content parts (SMCCONTENT-TITLE, SMCCONTENT-ABSTRACT, SMCCONTENT-BODY, etc.) with their corresponding filter configurations (default or okf_html). Uses CDATA sections in output, bilingual mode with SOURCE_ID and LOCALE_ID identification.","input":"partsNames=SMCCONTENT-TITLE, SMCCONTENT-ABSTRACT, SMCCONTENT-BODY, SMCCONTENT-ALT, SMCCHANNELDESCRIPTOR-TITLE, SMCCHANNELDESCRIPTOR-ABSTRACT, SMCCHANNELDESCRIPTOR-ALT, SMCLINKCOLLECTIONS-LINKCOLLECTION-TITLE, SMCLINKCOLLECTIONS-LINKCOLLECTION-DESCRIPTION, SMCLINKS-TITLE, SMCLINKS-ABSTRACT, SMCLINKS-BODY, SMCLINKS-ALT\npartsConfigurations=default, okf_html, okf_html, default, default, okf_html, default, default, okf_html, default, okf_html, okf_html, default\nmonolingual=false\nuseCDATA=true"},{"title":"Escaped HTML configuration (without CDATA)","description":"Alternative configuration for Vignette files that do not use CDATA sections. The content is escaped HTML instead. Uses the same parts and filter mappings as the default, but with useCDATA set to false and quoteMode explicitly defined.","input":"partsNames=SMCCONTENT-TITLE, SMCCONTENT-ABSTRACT, SMCCONTENT-BODY, SMCCONTENT-ALT, SMCCHANNELDESCRIPTOR-TITLE, SMCCHANNELDESCRIPTOR-ABSTRACT, SMCCHANNELDESCRIPTOR-ALT, SMCLINKCOLLECTIONS-LINKCOLLECTION-TITLE, SMCLINKCOLLECTIONS-LINKCOLLECTION-DESCRIPTION, SMCLINKS-TITLE, SMCLINKS-ABSTRACT, SMCLINKS-BODY, SMCLINKS-ALT\npartsConfigurations=default, okf_html, okf_html, default, default, okf_html, default, default, okf_html, default, okf_html, okf_html, default\nmonolingual=false\nuseCDATA=false\nquoteModeDefined=true\nquoteMode=0"}],"filterId":"okf_vignette","wikiUrl":"https://okapiframework.org/wiki/index.php/vignette_filter"},"okf_wiki":{"filterName":"Wiki Filter","overview":"The Wiki Filter is an Okapi component for extracting translatable text from wiki markup. Currently the only supported style of markup is Dokuwiki. It extracts translatable content from headers, paragraphs, list items, image captions, and table cells/headers.","parameters":{"preserve_whitespace":{"description":"When set to true, prevents the filter from collapsing whitespace in the extracted text. When false (the default), consecutive whitespace characters are collapsed. Set via the YAML parameter 'preserve_whitespace: true'.","notes":[]},"simplifierRules":{"description":"Rules for simplifying inline code representation. Used to define how inline codes are presented in the extracted text.","notes":[]},"path":{"description":"Path to an external YAML parameters file for the filter configuration.","notes":[]}},"limitations":["Attributes of inline codes (link and image URLs, etc.) are not exposed for translation or special processing.","Embedded HTML, PHP, etc., is not extracted."],"processingNotes":["If the file has a Unicode Byte-Order-Mark, the corresponding encoding (e.g. UTF-8, UTF-16, etc.) is used. Otherwise, the input encoding used is the default encoding that was specified when opening the document.","All Dokuwiki syntax as described in the Dokuwiki syntax reference is supported for inline codes.","Custom inline codes can be defined using 'custom_codes' in the YAML configuration with either a 'pattern' for placeholder tags or a 'start_pattern'/'end_pattern' pair for opening/closing tag pairs. Patterns are regular expressions that match non-zero-width runs of text."],"examples":[{"title":"Extractable content from Dokuwiki markup","description":"Shows which parts of Dokuwiki markup are extracted as translatable text units. Headers, paragraphs, list items, image captions, and table cells/headers are all extracted.","input":"=== Header ===\nParagraph\n * List item\n  * List item\n\n{{image.jpg|Image caption}}\n\n^ Table header 1 ^ Table header 2 |\n| Table cell 1 | Table cell 2 |","output":"Extracted text units: 'Header', 'Paragraph', 'List item' (x2), 'Image caption', 'Table header 1', 'Table header 2', 'Table cell 1', 'Table cell 2'"},{"title":"Custom inline code with placeholder pattern","description":"Defines a custom inline code using a single regex pattern for placeholder-style tags that appear within translatable text.","input":"custom_codes:\n  - pattern: \"\\[(path|menu)[^\\]]*\\]\"","output":"Matches within translatable text are turned into inline codes (placeholders)."},{"title":"Custom inline code with start/end pattern pair","description":"Defines a custom inline code using start and end regex patterns for opening/closing tag pairs within translatable text.","input":"custom_codes:\n  - {start_pattern: \"REGEX_PATTERN\", end_pattern: \"REGEX_PATTERN\"}","output":"Matched start/end pairs are turned into opening/closing inline code tags within translatable text."}],"filterId":"okf_wiki","wikiUrl":"https://okapiframework.org/wiki/index.php/wiki_filter"},"okf_wsxzpackage":{"filterName":"WSXZ Package Filter","overview":"The WSXZ Package Filter is an Okapi component that implements the IFilter interface for WSXZ (Worldserver TKIT) files. It is an extension of the Archive Filter that reads input packages, detects SDLXLIFF files for a specified language pair, and uses the XLIFF Filter (with the okf_xliff-sdl configuration) to process the content. Each SDLXLIFF file inside the package corresponds to a sub-document in the Okapi filter events.","parameters":{"mimeType":{"description":"The MIME type of the filter's container format. Defaults to 'application/x-archive'. This is inherited from the Archive Filter base."},"fileNames":{"description":"Comma-delimited list of file names to be processed within the archive. Wildcards are allowed (e.g., '*.tmx,*.xlf,*.xlff'). The file names must be listed in the same order as the corresponding configuration IDs in the configIds parameter. Although the default includes TMX and XLIFF patterns, in practice the filter detects SDLXLIFF files for the specified language pair and processes them using the XLIFF Filter with the okf_xliff-sdl configuration.","dependsOn":[{"property":"configIds","condition":"must have entries in the same order corresponding to each file name pattern"}]},"configIds":{"description":"Comma-delimited list of Okapi filter configuration IDs, each corresponding to a file name pattern in the fileNames parameter. For example, 'okf_tmx,okf_xliff,okf_xliff' maps the first fileNames entry to the TMX filter and the second and third to the XLIFF filter. In actual WSXZ processing, the filter uses the okf_xliff-sdl configuration for SDLXLIFF content.","dependsOn":[{"property":"fileNames","condition":"must have entries in the same order corresponding to each configuration ID"}]},"moveLeadingAndTrailingCodesToSkeleton":{"description":"When enabled, inline codes (tags/placeholders) that appear at the beginning or end of a segment are moved out of the translatable content and into the skeleton (non-translatable portion). This can simplify the text presented to translators by removing boundary codes that do not need translation."},"mergeAdjacentCodes":{"description":"When enabled, consecutive inline codes that appear next to each other are merged into a single placeholder. This reduces the number of inline codes translators must handle and simplifies the segment representation."},"simplifierRules":{"description":"Rules for simplifying the inline code representation in extracted content. These rules define how complex inline code sequences should be simplified for easier translation processing. Configured via a dedicated simplifier rules editor."}},"limitations":["TMX and TBX files within the WSXZ package are ignored.","Subject to all the limitations of the XLIFF Filter, since SDLXLIFF content is processed using that filter."],"processingNotes":["The filter is an extension of the Archive Filter.","It reads the input WSXZ package and detects SDLXLIFF files for the specified language pair.","SDLXLIFF files are processed using the XLIFF Filter with the okf_xliff-sdl configuration.","Each SDLXLIFF file inside the package corresponds to a sub-document in the Okapi filter events."],"examples":[],"filterId":"okf_wsxzpackage","wikiUrl":"https://okapiframework.org/wiki/index.php/wsxz_package_filter"},"okf_xliff":{"filterName":"XLIFF Filter","overview":"The XLIFF Filter is an Okapi component that implements the IFilter interface for XLIFF 1.2 (XML Localisation Interchange File Format) documents. XLIFF is an OASIS Standard that defines a file format for transporting translatable text and localization-related information across a chain of translation and localization tools. The filter supports segmentation handling, alt-trans elements, ITS annotations, and has specialized configurations for SDLXLIFF and IWS XLIFF variants.","parameters":{"fallbackToID":{"description":"When enabled, uses the value of the 'id' attribute of the <trans-unit> element as a fall-back value for the text unit name if 'resname' is not present. This is useful for XLIFF documents that use resname-like values for 'id' but do not provide 'resname' as they should.","notes":[]},"ignoreInputSegmentation":{"description":"When enabled, ignores any segmentation information contained in the input XLIFF. All segmented content is reduced to new unsegmented content when extracted.","notes":["Note: Any <alt-trans> data attached to a given segment is also lost when this option is set."]},"addTargetLanguage":{"description":"When enabled, adds the 'target-language' attribute in <file> elements if it is not already present.","notes":[]},"overrideTargetLanguage":{"description":"When enabled, overrides the language of the target set in the input XLIFF. The value of the 'target-language' attribute and the value of 'xml:lang' in all <target> elements are set to the target language specified by the user, regardless of their original values. This is useful when using an XLIFF document as a template for several outputs in different target languages.","notes":["Note: Depending on what the original XLIFF document contains, this option may result in outputs where existing <alt-trans> elements do not correspond to the target language of a given <trans-unit> anymore."]},"allowEmptyTargets":{"description":"When enabled, allows empty <target> elements in the XLIFF document by preventing copying of source text into an empty target.","notes":[]},"outputSegmentationType":{"description":"Selects the type of segmentation representation to use for the output. Valid values: 0 = 'Segment only if the input text unit is segmented' (each text unit uses <seg-source> only if the original was already represented that way); 1 = 'Always segment' (each text unit uses <seg-source> even if the original was not segmented or has only a single segment); 2 = 'Never segment' (no text units are segmented, all <seg-source> elements are removed); 3 = 'Segment only if the entry is segmented and regardless how the input was' (only text units with more than one part are segmented, regardless of input).","notes":[]},"addAltTrans":{"description":"When enabled, allows the addition of new <alt-trans> elements in the output. For example, when this option is set and the Leveraging Step is applied to a given XLIFF input document, its output includes the translation matches possibly found during leveraging.","notes":[]},"addAltTransGMode":{"description":"When enabled, uses the <g>/<x> notation for inline codes (instead of the <bpt>/<ept>/<ph> notation) in newly added <alt-trans> elements.","dependsOn":[{"property":"addAltTrans","condition":"must be true for this setting to have effect, since it controls notation in added <alt-trans> elements"}],"notes":[]},"editAltTrans":{"description":"When enabled, allows <alt-trans> elements that exist in the input to be modified in the output. The existing entries will be treated like added ones.","notes":[]},"includeExtensions":{"description":"When enabled, includes non-standard extra information (e.g. match types) in the added <alt-trans> elements.","dependsOn":[{"property":"addAltTrans","condition":"must be true for this setting to have effect, since extra information is added to <alt-trans> elements"}],"notes":[]},"useCustomParser":{"description":"When enabled, uses an XML stream parser different from the default one. The default parser for this filter is the Woodstox XML parser. The reason for using a custom parser is that the Java parser that comes with most VMs implements the collapsing of whitespace characters using a recursive method that can cause a stack overflow error in XLIFF documents with large chunks of element content (e.g. in SDLXLIFF files).","notes":[]},"factoryClass":{"description":"The name of the factory class that will instantiate the custom XML stream parser to use. For example: 'com.ctc.wstx.stax.WstxInputFactory'.","dependsOn":[{"property":"useCustomParser","condition":"must be true for this setting to take effect"}],"notes":[]},"includeIts":{"description":"When enabled, includes ITS (Internationalization Tag Set) and ITSXLF annotations found in the XLIFF document. These annotations provide localization-related metadata such as translate flags, terminology markers, and other ITS data categories.","notes":[]},"targetStateMode":{"description":"Controls how the 'state' attribute on <target> elements is handled during output. An integer value that determines whether and how target state values are set or modified.","notes":[]},"targetStateValue":{"description":"The value to use for the 'state' attribute on <target> elements when targetStateMode is configured to set a state value. Default is 'needs-translation'. Common XLIFF state values include: new, needs-translation, needs-review-translation, translated, final, etc.","dependsOn":[{"property":"targetStateMode","condition":"must be set to a mode that applies target state values"}],"notes":[]},"alwaysUseSegSource":{"description":"When enabled, always reads content from the <seg-source> element rather than <source>, even when the content is not segmented. Normally <seg-source> is only used when segmentation markers are present.","notes":[]},"preserveSpaceByDefault":{"description":"When enabled, treats all content as if xml:space='preserve' is set by default, preserving whitespace in source and target content. When disabled, content without an explicit xml:space='preserve' attribute is unwrapped (whitespace collapsed).","notes":[]},"useSdlXliffWriter":{"description":"When enabled, uses the SDL-specific XLIFF writer for output, which handles SDL-specific metadata and formatting conventions found in SDLXLIFF files.","notes":[]},"sdlSegLockedValue":{"description":"The value to set for the SDL 'locked' property on segments. Used when writing SDLXLIFF files to control the locked status of segments.","dependsOn":[{"property":"useSdlXliffWriter","condition":"must be true for SDL-specific properties to be written"}],"notes":["Note: SDL properties locked, conf, and origin are stored in the TextContainer of the target rather than in each segment. If there are several segments, the values are those of the last segment. From M35 on, the three properties are also stored at the segment level with correct values, but those segment-level properties are read-only."]},"sdlSegConfValue":{"description":"The value to set for the SDL 'conf' (confirmation) property on segments. Used when writing SDLXLIFF files to indicate the confirmation level of segments (e.g. 'Translated', 'ApprovedTranslation', 'Draft').","dependsOn":[{"property":"useSdlXliffWriter","condition":"must be true for SDL-specific properties to be written"}],"notes":["Note: SDL properties locked, conf, and origin are stored in the TextContainer of the target rather than in each segment. If there are several segments, the values are those of the last segment. From M35 on, the three properties are also stored at the segment level with correct values, but those segment-level properties are read-only."]},"sdlSegOriginValue":{"description":"The value to set for the SDL 'origin' property on segments. Used when writing SDLXLIFF files to indicate the origin of the translation (e.g. 'mt' for machine translation, 'tm' for translation memory).","dependsOn":[{"property":"useSdlXliffWriter","condition":"must be true for SDL-specific properties to be written"}],"notes":["Note: SDL properties locked, conf, and origin are stored in the TextContainer of the target rather than in each segment. If there are several segments, the values are those of the last segment. From M35 on, the three properties are also stored at the segment level with correct values, but those segment-level properties are read-only."]},"skipNoMrkSegSource":{"description":"When enabled, skips <seg-source> elements that contain no explicit <mrk mtype='seg'> segment markers. Such elements are treated as if the whole content is a single unsegmented source.","notes":[]},"subAsTextUnit":{"description":"When enabled, extracts the content of <sub> elements as separate text units rather than including them as inline codes within their parent elements (<bpt>, <ept>, <ph>, <it>).","notes":["Note: By default, <sub> element content is included in the code of the parent inline element, and a warning is generated when a <sub> element is detected."]},"useSegsForSdlProps":{"description":"When enabled, uses segment-level SDL properties (locked, conf, origin) rather than container-level properties. Available from M35 onwards, where SDL properties are stored at both the segment level and container level.","dependsOn":[{"property":"useSdlXliffWriter","condition":"must be true for SDL-specific property handling"}],"notes":[],"introducedIn":"M35"},"useTranslationTargetState":{"description":"When enabled, uses the 'state' attribute from <target> elements to determine translation status. This allows the filter to interpret XLIFF target state values for downstream processing.","notes":[]},"alwaysAddTargets":{"description":"When enabled, always adds <target> elements to the output even if they were not present in the input. This ensures every <trans-unit> in the output contains a <target> element.","notes":[]},"useIwsXliffWriter":{"description":"When enabled, uses the IWS-specific XLIFF writer for output, which handles IWS-specific metadata and formatting conventions found in IWS XLIFF files.","notes":[]},"iwsBlockFinished":{"description":"When enabled, blocks (protects from further changes) translation units that have a finished status in IWS XLIFF documents.","dependsOn":[{"property":"useIwsXliffWriter","condition":"must be true for IWS-specific processing"}],"notes":[]},"iwsTransStatusValue":{"description":"The translation status value to set for entries in IWS XLIFF documents. Common values include 'finished' and 'pending'.","dependsOn":[{"property":"useIwsXliffWriter","condition":"must be true for IWS-specific processing"}],"notes":[]},"iwsRemoveTmOrigin":{"description":"When enabled, removes the TM (translation memory) origin information from IWS XLIFF entries during output.","dependsOn":[{"property":"useIwsXliffWriter","condition":"must be true for IWS-specific processing"}],"notes":[]},"iwsTransTypeValue":{"description":"The translation type value to set for entries in IWS XLIFF documents. Common values include 'manual_translation' and 'machine_translation'.","dependsOn":[{"property":"useIwsXliffWriter","condition":"must be true for IWS-specific processing"}],"notes":[]},"iwsBlockLockStatus":{"description":"When enabled, blocks (write-protects) translation units based on their lock status in IWS XLIFF documents.","dependsOn":[{"property":"useIwsXliffWriter","condition":"must be true for IWS-specific processing"}],"notes":[]},"iwsBlockTmScore":{"description":"When enabled, blocks (write-protects) translation units that have a TM match score at or above the threshold specified by iwsBlockTmScoreValue.","dependsOn":[{"property":"useIwsXliffWriter","condition":"must be true for IWS-specific processing"}],"notes":[]},"iwsBlockTmScoreValue":{"description":"The TM match score threshold for blocking translation units. When iwsBlockTmScore is enabled, entries with a score at or above this value are blocked. Default is '100.00'. Value is a string representing a decimal number.","dependsOn":[{"property":"iwsBlockTmScore","condition":"must be true for this threshold to be applied"},{"property":"useIwsXliffWriter","condition":"must be true for IWS-specific processing"}],"notes":[]},"iwsIncludeMultipleExact":{"description":"When enabled, includes multiple exact TM matches in the output for IWS XLIFF documents, rather than keeping only the first exact match.","dependsOn":[{"property":"useIwsXliffWriter","condition":"must be true for IWS-specific processing"}],"notes":[]},"iwsBlockMultipleExact":{"description":"When enabled, blocks (write-protects) translation units that have multiple exact TM matches in IWS XLIFF documents.","dependsOn":[{"property":"useIwsXliffWriter","condition":"must be true for IWS-specific processing"}],"notes":[]},"forceUniqueIds":{"description":"When enabled, forces all trans-unit IDs to be unique across the document by modifying duplicate IDs. This is useful for XLIFF documents that contain non-unique trans-unit IDs which can cause issues in downstream processing.","notes":[]},"inlineCdata":{"description":"When enabled, processes CDATA sections inline within the content rather than treating them as separate blocks. This affects how CDATA content in source and target elements is handled during extraction.","notes":[]},"xtmAttributes":{"description":"When enabled, handles XTM-specific attributes in the XLIFF document. XTM is a translation management system that may add custom attributes to XLIFF elements.","notes":[]},"useCodeFinder":{"description":"When enabled, activates pattern-based detection of inline codes (placeholders, tags, etc.) within translatable text using the regex patterns defined in codeFinderRules.","notes":[]},"codeFinderRules":{"description":"Defines the regex patterns used to identify inline codes in translatable text. Contains a list of regex rules, a sample text for testing patterns, and a flag to control whether all rules are tested together or individually.","dependsOn":[{"property":"useCodeFinder","condition":"must be true for code finder rules to be applied"}],"notes":[]},"cdataSubfilter":{"description":"Specifies a sub-filter to apply to CDATA sections found in the XLIFF content. The value should be a filter configuration ID (e.g. 'okf_html'). When set, CDATA content is processed by the specified sub-filter for further extraction.","notes":[]},"pcdataSubfilter":{"description":"Specifies a sub-filter to apply to PCDATA (parsed character data) content in the XLIFF document. The value should be a filter configuration ID. When set, PCDATA content is processed by the specified sub-filter for further extraction.","notes":[]},"moveLeadingAndTrailingCodesToSkeleton":{"description":"When enabled, moves inline codes that appear at the very beginning or end of a segment to the skeleton (non-translatable portion). This simplifies the translatable content by removing boundary codes that do not need to be seen by translators.","notes":[]},"mergeAdjacentCodes":{"description":"When enabled, merges consecutive inline codes that appear next to each other into a single placeholder. This reduces the number of inline code placeholders that translators need to manage.","notes":[]},"simplifierRules":{"description":"Rules for simplifying inline code representation in extracted text. These rules define how complex inline code sequences should be collapsed or simplified to make translatable content easier to work with.","notes":[]}},"limitations":["The content of <sub> elements is currently not supported as text. Any element found inside <bpt>, <ept>, <ph>, and <it> (including <sub>) is included in the code of the parent inline element. A warning is generated when a <sub> element is detected.","The special marker <mrk mtype='protected'> is supported by converting the content into an inline code. However, if a marker <mrk mtype='x-its-translate-yes'> is used within such a marker, it is not supported and its content is placed into the original data part of the inline code.","In SDLXLIFF files, the SDL properties 'locked', 'conf', and 'origin' are stored in the TextContainer of the target rather than in each segment. If there are several segments, the values are those of the last segment. From M35 on, the three properties are also stored at the segment level with correct values, but those segment-level properties are read-only."],"processingNotes":["Input encoding: If the document has an encoding declaration it is used; otherwise, UTF-8 is used as the default encoding regardless of the actual default encoding specified when opening the document.","Output BOM handling: If input and output are both UTF-8, a BOM is written only if one was detected in the input. If input was not UTF-8, no BOM is written.","Line-breaks in the output match the type of line-breaks found in the original input.","White space handling depends on xml:space attribute: if <trans-unit> has xml:space='preserve', whitespace in source and target content is preserved; otherwise content is unwrapped.","The <seg-source> segmentation is discarded if its content (without segment markers) does not match the content of the <source> element.","If <seg-source> has no explicit <mrk mtype='seg'> element, it is treated as if the whole content is a single segment.","Alt-trans entries are sorted based on match types and score. The match-quality attribute is used as score if it is an integer or percentage; otherwise score is set to 0.","Alt-trans origin defaults to 'SourceDoc' if no origin attribute is present.","The maxbytes attribute maps to the its-storageSize property. If its:storageSizeEncoding is present, its value is used; otherwise UTF-8 is the default encoding for byte length computation. Note that its:storageSize is not recognized; the size must be declared using maxbytes."],"examples":[{"title":"Alt-trans match type inference","description":"When no explicit Okapi matchType extension attribute is present on an <alt-trans> element, the filter infers match types from the match-quality score: EXACT if score > 99, FUZZY if score > 0, and 0 (unknown) otherwise.","input":"<alt-trans match-quality=\"100%\" origin=\"MyTM\">\n  <source xml:lang=\"en\">Hello</source>\n  <target xml:lang=\"fr\">Bonjour</target>\n</alt-trans>","output":"AltTranslationsAnnotation with score=100, matchType=EXACT, origin=\"MyTM\""},{"title":"Output segmentation type options","description":"The outputSegmentationType parameter controls how segmentation is represented in the output. Value 0: segment only if input was segmented. Value 1: always add <seg-source>. Value 2: never segment (remove all <seg-source>). Value 3: segment only if entry has multiple parts, regardless of input.","input":"outputSegmentationType=1 (Always segment)","output":"All <trans-unit> elements in output will have <seg-source> with <mrk mtype='seg'> markers, even if the input had no segmentation."},{"title":"SDLXLIFF configuration","description":"The predefined okf_xliff-sdl configuration enables SDL-specific handling: useCustomParser=true with Woodstox factory class to avoid stack overflow on large SDLXLIFF files, useSdlXliffWriter=true for SDL metadata, preserveSpaceByDefault=true, and skipNoMrkSegSource=true.","input":"configId: okf_xliff-sdl","output":"Uses Woodstox parser, SDL writer, preserves whitespace, skips seg-source without mrk markers."},{"title":"IWS XLIFF configuration","description":"The predefined okf_xliff-iws configuration enables IWS-specific handling with useIwsXliffWriter=true and various IWS-specific blocking and status settings for managing translation workflow states.","input":"configId: okf_xliff-iws","output":"Uses IWS writer with iwsBlockFinished=true, iwsTransStatusValue='pending', iwsTransTypeValue='manual_translation'."}],"filterId":"okf_xliff","wikiUrl":"https://okapiframework.org/wiki/index.php/xliff_filter"},"okf_xliff2":{"filterName":"XLIFF-2 Filter","overview":"The XLIFF-2 Filter is an Okapi component that implements the IFilter interface for XLIFF 2.x (XML Localisation Interchange File Format) documents. XLIFF v2 is an OASIS Standard that defines a file format for transporting translatable text and localization-related information across a chain of translation and localization tools. The filter provides basic support for XLIFF 2.x core including extended attributes, namespaces, segments, ignorables, inline codes, notes, groups, and the XLIFF 2.x Metadata Module.","parameters":{"maxValidation":{"description":"When enabled, the XLIFF-2 parser used by the filter performs the maximum verification of the format during parsing. This ensures strict compliance checking of the XLIFF 2.x document structure."},"useCodeFinder":{"description":"When enabled, the filter uses the inline code finder rules defined in codeFinderRules to detect inline codes within the text content. This allows additional patterns beyond the standard XLIFF inline elements to be recognized as codes."},"codeFinderRules":{"description":"Configuration for inline code detection. Contains a list of regex patterns used to identify inline codes within text content, a sample text for testing the patterns, and a flag controlling whether all rules are tested together or individually.","dependsOn":[{"property":"useCodeFinder","condition":"must be true for these rules to be applied"}]},"simplifyTags":{"description":"When enabled, simplifies the tag structure in the extracted content."},"needsSegmentation":{"description":"When enabled, resegments any unit that is marked with canSegment=\"yes\". Units with an existing target cannot be segmented, so segmentation only applies to source-only units eligible for segmentation."},"forceUniqueIds":{"description":"When enabled, ensures that tag IDs are unique within each translation unit. This can help resolve issues when inline code IDs are duplicated within a unit."},"ignoreTagTypeMatch":{"description":"When enabled, ignores tag type mismatches between source and target content. Normally the filter validates that corresponding tags in source and target are of the same type; this option relaxes that validation."},"discardInvalidTargets":{"description":"When enabled, invalid targets are silently discarded rather than causing the filter to reject the entire file. This allows processing of documents that contain some malformed target elements."},"writeOriginalData":{"description":"When enabled, the output includes original data when available. Original data refers to the native markup or formatting information stored in XLIFF originalData elements."},"subfilterOverwriteTarget":{"description":"Controls whether the writer should always overwrite an existing target even if the translation state is final. When enabled, the subfilter output will replace existing target content regardless of its state."}},"limitations":["Skeleton not supported.","Comments are lost in the merged document.","Original XML formatting lost in merged document.","Attributes can be reordered.","Attributes may be removed or added compared to the original depending on the default values and logic in the XLIFF 2 Toolkit."],"processingNotes":["Provides basic support for XLIFF 2.x core.","Supports extended attributes and namespaces.","Supports segments and ignorables.","Supports inline codes.","Supports notes and groups.","Supports XLIFF 2.x Metadata Module."],"examples":[],"filterId":"okf_xliff2","wikiUrl":"https://okapiframework.org/wiki/index.php/xliff_2_filter"},"okf_xml":{"filterName":"XML Filter","overview":"The XML Filter processes XML documents using a DOM-based parser, which allows it to implement the W3C Internationalization Tag Set (ITS) standard. It determines translatable content, inline elements, and other localization aspects through ITS rules defined either inline in the document or in an external parameters file. Because each XML-based format is different, the filter relies on ITS global and local rules (supporting both ITS 1.0 and 2.0) plus Okapi-specific extensions to identify what should be extracted for translation. For very large XML documents where ITS is not needed, the XML Stream Filter may be more appropriate.","parameters":{"simplifierRules":{"description":"Rules for simplifying inline code representation. These rules define how inline codes detected by the code finder or from XML markup are simplified into a more compact representation for translation tools."},"path":{"description":"Path to the ITS rules file (.fprm) used as the filter's parameters. The parameters file is an ITS document (XML format) that specifies global and local rules for processing XML documents. It can contain ITS translate rules, within-text rules, locale filter rules, and Okapi-specific filter options using the namespace URI 'okapi-framework:xmlfilter-options'. Filter options must be placed in this parameters file — options placed in embedded or linked ITS rules within the document itself have no effect. The file supports ITS 1.0 and 2.0, plus Okapi extensions for idValue, whiteSpaces, and filter options (lineBreakAsCode, codeFinder, omitXMLDeclaration, escapeQuotes, escapeGT, escapeNbsp, extractIfOnlyCodes, inlineCdata, extractUntranslatable).","notes":["The filter options must be placed in the parameters file (.fprm) used with the filter, not in embedded or linked ITS rules. Options placed in embedded or linked ITS rules have no effect.","When you use several options, they must be set in a single <okp:options> element."]}},"limitations":["In some cases, the ITS rule withinTextRule with the value 'nested' may act like it has a value 'yes' instead.","In output, the values of xml:lang attributes are not updated to reflect the target language.","When doing extraction, the whole input file is loaded into memory. You may run into memory limitations if the document is very large."],"processingNotes":["If the document has an encoding declaration it is used; otherwise, UTF-8 is used as the default encoding regardless of any default encoding specified when opening the document.","If the output encoding is UTF-8 and the input was also UTF-8, a Byte-Order-Mark is used only if one was detected in the input. If the input was not UTF-8, no BOM is used.","If the original document had an XML encoding declaration it is updated; if it did not, one is automatically added.","The type of line-breaks in the output is the same as the original input.","By default, all element content is translatable and no attribute values are translatable (ITS defaults). Different behavior occurs if the input document contains ITS markup or if a filter parameters file is specified.","The filter supports ITS 1.0 and ITS 2.0 (2.0 is backward compatible with 1.0).","The whole input file is loaded into memory (DOM-based parser), which may cause issues with very large documents."],"examples":[{"title":"Code Finder for inline codes","description":"Parameters file defining code finder rules to detect XML-like tags and variable placeholders as inline codes. Rule0 matches XML tags like <b>, </b>, <br/>. Rule1 matches words in # or numbers in % like #VAR# or %1%. Set useCodeFinder to 'yes' to activate. The first line must be #v1, count.i=N must precede rules, ruleN is 0-indexed, and patterns must be XML-escaped.","input":"<its:rules version=\"1.0\"\n xmlns:its=\"http://www.w3.org/2005/11/its\"\n xmlns:okp=\"okapi-framework:xmlfilter-options\">\n <okp:codeFinder useCodeFinder=\"yes\">#v1\ncount.i=2\nrule0=&lt;(/?)\n+[^&gt;]*?&gt;\nrule1=(#\\w+?\\#)|(%\\d+?%)\n </okp:codeFinder>\n</its:rules>","output":"Matched spans within extracted text are treated as inline codes (placeholders) rather than translatable text."},{"title":"ITS translate rules with idValue","description":"Using the itsx:idValue extension to assign resource names from XPath expressions. The @name attribute value is used as the text unit identifier. Note: xml:id has precedence over idValue declarations.","input":"<doc>\n <its:rules version=\"1.0\" xmlns:its=\"http://www.w3.org/2005/11/its\"\n  xmlns:itsx=\"http://www.w3.org/2008/12/its-extensions\">\n  <its:translateRule selector=\"//p\" translate=\"yes\" itsx:idValue=\"@name\"/>\n </its:rules>\n <p name=\"id1\">text 1</p>\n</doc>","output":"Text unit with resource name 'id1' containing 'text 1'."},{"title":"Combining multiple filter options","description":"When using several filter options, they must be set in a single <okp:options> element. This example enables lineBreakAsCode, disables quote escaping, and enables greater-than escaping.","input":"<its:rules version=\"1.0\"\n xmlns:its=\"http://www.w3.org/2005/11/its\"\n xmlns:okp=\"okapi-framework:xmlfilter-options\">\n <okp:options lineBreakAsCode=\"yes\"\n              escapeQuotes=\"no\"\n              escapeGT=\"yes\"\n />\n</its:rules>","output":"Line breaks in content become inline codes, double quotes in element content are not escaped, and > characters are escaped."},{"title":"Extracting untranslatable content with exclusions","description":"Using extractUntranslatable to extract non-translatable content for context, while using localeFilterList to exclude specific tags from extraction.","input":"<its:rules version=\"1.0\"\n xmlns:its=\"http://www.w3.org/2005/11/its\"\n xmlns:okp=\"okapi-framework:xmlfilter-options\">\n <okp:options extractUntranslatable=\"yes\"/>\n <its:localeFilterRule selector=\"//yourTagThatShouldNotBeExtracted\" localeFilterList=\"!*\"/>\n</its:rules>","output":"Contents marked its:translate=\"no\" are extracted but marked as translate=\"no\" in XLIFF, except elements matching the localeFilterRule which are excluded entirely."},{"title":"WhiteSpaces extension for preserving spaces","description":"Using the itsx:whiteSpaces extension to globally apply space preservation equivalent to xml:space=\"preserve\" for specific elements. Note: xml:space attribute has precedence over this extension. This was defined for ITS 1.0; ITS 2.0 offers the Preserve Space data category instead.","input":"<its:rules version=\"1.0\" xmlns:its=\"http://www.w3.org/2005/11/its\"\n xmlns:itsx=\"http://www.w3.org/2008/12/its-extensions\">\n <its:translateRule selector=\"//pre\" translate=\"yes\" itsx:whiteSpaces=\"preserve\"/>\n</its:rules>","output":"Spaces, tabs, and line breaks in <pre> elements will be preserved on extraction."}],"filterId":"okf_xml","wikiUrl":"https://okapiframework.org/wiki/index.php/xml_filter"},"okf_xmlstream":{"filterName":"XML Stream Filter","overview":"The XML Stream Filter is an Okapi component that implements the IFilter interface for XML documents using a stream parser, which allows processing much larger documents than DOM-based parsers like the XML Filter. It uses the same YAML-based configuration as the HTML Filter, supporting element rules, attribute rules, CDATA/PCDATA sub-filtering, and quote mode configuration. If you need ITS (Internationalization Tag Set) support, use the XML Filter instead.","parameters":{"assumeWellformed":{"description":"When true, the filter assumes the input XML document is well-formed and skips well-formedness checks. This is typically set to true for XML content since XML is expected to be well-formed by definition. Set to false if you need the parser to handle potentially malformed XML more gracefully.","notes":[]},"preserve_whitespace":{"description":"When true, whitespace in the document is preserved globally as-is. When false (the default), whitespace may be normalized. This is the global default; individual elements can override this behavior using the PRESERVE_WHITESPACE rule type in their element rules, or via xml:space attribute handling configured in the attributes section.","notes":[]},"attributes":{"description":"Global attribute extraction rules that apply across all elements in the document. This is a map where each key is an attribute name (e.g., 'xml:lang', 'xml:id', 'id', 'xml:space') and each value is an attribute rule object specifying how that attribute should be handled. Attribute names must be in lowercase in the configuration file. Attributes with a namespace prefix should be declared with the prefix and enclosed in single quotes (e.g., 'xml:lang'). Available rule types for attributes are: ATTRIBUTE_TRANS (translatable attribute), ATTRIBUTE_WRITABLE (modifiable but non-translatable, e.g., xml:lang for locale writing), ATTRIBUTE_READONLY (extracted but cannot be modified), ATTRIBUTE_ID (provides segment identification), and ATTRIBUTE_PRESERVE_WHITESPACE (controls whitespace preservation via attribute conditions). The ATTRIBUTE_PRESERVE_WHITESPACE rule type supports 'preserve' and 'default' condition arrays to control whitespace behavior based on attribute values (e.g., preserve: ['xml:space', EQUALS, preserve]). Each attribute rule can optionally include 'allElementsExcept' (apply to all elements except listed ones) or 'onlyTheseElements' (apply only to listed elements) to scope the rule.","notes":["All attribute names should be in lowercase in the configuration file.","Attributes with a prefix should be declared with the prefix and between single quotes."]},"simplifierRules":{"description":"Rules for simplifying inline code representation in extracted text. These rules control how inline codes (tags, placeholders) are presented to translators, potentially replacing complex markup with simpler placeholder representations.","notes":[]},"taggedConfig":{"description":"Tagged configuration object for internal filter configuration management. This is an internal parameter used by the filter framework.","notes":[]},"editorTitle":{"description":"Title displayed in the parameters editor UI. Defaults to 'Parameters Editor'.","notes":[]},"path":{"description":"Path to the YAML configuration file for the filter parameters.","notes":[]}},"limitations":["There is no transparent support for namespace prefixes: element names must be declared with their prefix in the configuration (e.g., use 'my:element' rather than just 'element').","The filter is not case-sensitive — elements like <elem> and <Elem> are treated as identical, which violates the XML specification that requires case-sensitive element names.","The escapeCharacters parameter from the HTML Filter is not available in the XML Stream Filter.","ITS (Internationalization Tag Set) is not supported — use the XML Filter instead if ITS support is needed."],"processingNotes":["Input encoding: If the document has an encoding declaration, it is used. Otherwise, UTF-8 is used as the default encoding regardless of any default encoding specified when opening the document.","Output encoding (UTF-8): If the input was also UTF-8, a Byte-Order-Mark is written only if one was detected in the input. If the input was not UTF-8, no BOM is written.","If the original document had an XML encoding declaration it is updated in the output; if it did not, one is automatically added.","Line-breaks: The type of line-breaks in the output matches the original input document.","Uses a stream parser rather than DOM, enabling processing of much larger XML documents than the DOM-based XML Filter."],"examples":[{"title":"Default XML Stream configuration","description":"Basic YAML configuration for generic XML documents with standard attribute handling for xml:lang, xml:id, id, and xml:space.","input":"assumeWellformed: true\npreserve_whitespace: false\n\nattributes:\n  'xml:lang':\n    ruleTypes: [ATTRIBUTE_WRITABLE]\n  'xml:id':\n    ruleTypes: [ATTRIBUTE_ID]\n  'id':\n    ruleTypes: [ATTRIBUTE_ID]\n  'xml:space':\n    ruleTypes: [ATTRIBUTE_PRESERVE_WHITESPACE]\n    preserve: ['xml:space', EQUALS, preserve]\n    default: ['xml:space', EQUALS, default]"},{"title":"CDATA sub-filtering with HTML","description":"Configuration that applies HTML filtering to CDATA sections. Useful when XML documents contain embedded HTML within CDATA blocks that needs additional markup processing before translation.","input":"assumeWellformed: true\nglobal_cdata_subfilter: okf_html\npreserve_whitespace: false\n\nelements:\n  entry:\n    ruleTypes: [TEXTUNIT]\n    idAttributes: [key]"},{"title":"PCDATA sub-filtering for double-escaped HTML","description":"Configuration for processing XML that contains double-escaped HTML content in PCDATA. Only content matched as TEXTUNIT is passed to the subfilter; content matched with INCLUDE rules is not. The element containing the escaped HTML must match a TEXTUNIT rule.","input":"global_pcdata_subfilter: okf_html\nelements:\n  test:\n    ruleTypes: [TEXTUNIT]"},{"title":"Quote mode configuration","description":"Configuring quote escaping behavior. Four modes are available: 0 (UNESCAPED — do not escape single or double quotes), 1 (ALL — escape both to named entities), 2 (NUMERIC_SINGLE_QUOTES — double quotes to named entity, single quotes to numeric entity), 3 (DOUBLE_QUOTES_ONLY — escape double quotes only).","input":"quoteModeDefined: true\nquoteMode: 3"},{"title":"Conditional translatable attributes on elements","description":"Element rules with conditional translatable attributes. The image element is treated as inline only when its placement attribute does not equal 'break', and its alt attribute is extracted as translatable.","input":"elements:\n  image:\n    ruleTypes: [INLINE]\n    translatableAttributes: [alt]\n    conditions: [placement, NOT_EQUALS, break]"},{"title":"Regex-based conditional exclude/include","description":"Using regex-based element names with conditions to exclude elements where translate='no' and include elements where translate='yes'. The '.*' and '.+' patterns are a trick to work around YAML hashmap duplicate key restrictions while applying the same regex to both rules.","input":"elements:\n  '.*':\n    ruleTypes: [EXCLUDE]\n    conditions: [translate, EQUALS, 'no']\n  '.+':\n    ruleTypes: [INCLUDE]\n    conditions: [translate, EQUALS, 'yes']"}],"filterId":"okf_xmlstream","wikiUrl":"https://okapiframework.org/wiki/index.php/xml_stream_filter"},"okf_yaml":{"filterName":"YAML Filter","overview":"The YAML Filter is an Okapi component that implements the IFilter interface for YAML files and supports Ruby on Rails message variables. It extracts translatable string values from YAML key-value structures, including nested maps, lists, and quoted strings. Each extracted entry is assigned a name composed of the full sequence of its parent identifiers (e.g., \"fr/activerecord/errors/messages/exclusion\"). The filter is implemented in the class net.sf.okapi.filters.yaml.YamlFilter.","parameters":{"extractIsolatedStrings":{"description":"Extract strings that are not associated directly to a key value (stand-alone strings). When enabled, string values that appear without being part of a key-value pair are included in the extraction."},"extractAllPairs":{"description":"Controls extraction of strings that have an associated key. When set to true, all key/string pairs are extracted (unless they match the exceptions regex). When set to false, no key/string pairs are extracted (unless they match the exceptions regex, in which case the behavior is inverted — matching keys ARE extracted).","notes":["The exceptions regex inverts the default behavior: if extractAllPairs is true, matching keys are excluded; if false, matching keys are included."]},"exceptions":{"description":"A regular expression that corresponds to the keys that should have a behavior inverse to the default behavior selected for key/string pairs. When extractAllPairs is true, strings whose keys match this expression are NOT extracted. When extractAllPairs is false, strings whose keys match this expression ARE extracted. When useFullKeyPath is enabled, exception regular expressions apply to the full key path rather than just the immediate key.","dependsOn":[{"property":"extractAllPairs","condition":"inverts the behavior defined by extractAllPairs"},{"property":"useFullKeyPath","condition":"when true, exceptions apply to the full key path instead of just the immediate key"}]},"useKeyAsName":{"description":"Use the value of the YAML key as the name (resname) of the extracted item. In XLIFF output, this corresponds to the resname attribute. For example, in a YAML structure like 'messages: exclusion: \"text\"', the resname would be set to the key value."},"useFullKeyPath":{"description":"Use the full nested key path as the name (resname) instead of just the immediate key. For example, a deeply nested value would get a resname like 'menu/value/popup/menuitem/value' rather than just 'value'. The 'Use key as resname' option (useKeyAsName) must be enabled for this option to take effect. When enabled, exception regular expressions also apply to the full path rather than just the immediate key.","dependsOn":[{"property":"useKeyAsName","condition":"must be true for useFullKeyPath to take effect"}]},"useCodeFinder":{"description":"Enable pattern-based detection of inline codes (placeholders, tags, etc.) using the regular expressions defined in codeFinderRules. Any text matching the defined patterns will be converted to an inline code in the extracted content. This option cannot be used together with the sub-filtering option (subFilterProcessLiteralAsBlock).","notes":["This option cannot be used together with the sub-filtering option."],"dependsOn":[{"property":"subFilterProcessLiteralAsBlock","condition":"cannot be used when sub-filtering is enabled"}]},"codeFinderRules":{"description":"Configuration for inline code detection using regular expressions. Contains a set of regex rules that are applied to the text of extracted items; any match is converted to an inline code. The default expression matches printf-style format specifiers (e.g. %d, %s, %2$f), common escape sequences (\\n, \\r, \\t, \\a, \\b, \\f, \\v, \\r\\n), and numbered placeholders (e.g. {0}, {1}). Each rule must contain a valid regular expression. The sample field provides test text to verify patterns against. The useAllRulesWhenTesting option controls whether all rules are tested together or only the currently selected rule is tested — when enabled, the test takes all rules of the set into account.","dependsOn":[{"property":"useCodeFinder","condition":"must be true for codeFinderRules to be applied"}]},"subFilterProcessLiteralAsBlock":{"description":"Specify whether to process text content with a sub-filter. When enabled, the content of all translatable text is processed with a specified Okapi filter (e.g. okf_html). Leave the sub-filter field blank for default behavior. This option cannot be used together with the inline code finder (useCodeFinder).","notes":["This option cannot be used together with the inline code finder option (useCodeFinder)."],"dependsOn":[{"property":"useCodeFinder","condition":"cannot be used when useCodeFinder is enabled"}]},"escapeNonAscii":{"description":"When enabled, non-ASCII characters in the output are escaped. When disabled, non-ASCII characters are written as-is in the output encoding."},"wrap":{"description":"Controls line wrapping in the output. Note that wrapped lines in the original source document will be unwrapped in the target document regardless of this setting — all text will be placed on a single line. This parameter controls whether the output writer may re-wrap long lines."},"moveLeadingAndTrailingCodesToSkeleton":{"description":"Move inline codes that appear at the beginning or end of a segment (segment boundaries) to the skeleton (non-translatable framework). This cleans up the translatable content by removing codes that surround the text rather than being embedded within it."},"mergeAdjacentCodes":{"description":"Merge consecutive inline codes into a single placeholder. When multiple inline codes appear next to each other with no translatable text between them, they are combined into one code to simplify the translatable content."},"simplifierRules":{"description":"Rules for simplifying the inline code representation in extracted content. Allows defining patterns to reduce complex inline code structures into simpler representations for translators."}},"limitations":["Wrapped lines in the original source document will be unwrapped in the target document — all text will be placed on a single line.","If an illegal character is introduced during translation, the user will need to manually add double or single quotes to ensure the target YAML file is valid. A WARNING will be issued by the filter if this scenario can be detected.","The inline code finder (useCodeFinder) cannot be used together with the sub-filtering option (subFilterProcessLiteralAsBlock)."],"processingNotes":["If the file has a Unicode Byte-Order-Mark (BOM), the corresponding encoding (e.g. UTF-8, UTF-16) is used automatically.","If no BOM is present, the input encoding used is the default encoding that was specified when opening the document.","The type of line-breaks in the output matches the line-break style of the original input.","Each extracted entry is assigned a name composed of the full sequence of its parent identifiers, separated by slashes (e.g., 'fr/activerecord/errors/messages/exclusion')."],"examples":[{"title":"Ruby on Rails i18n YAML extraction","description":"Demonstrates extraction of translatable strings from a typical Ruby on Rails internationalization YAML file. All string values in key-value pairs are extracted, with names assigned based on the full key path.","input":"fr:\n  activerecord:\n    errors:\n      template:\n        header:\n          list: [one, two, three]\n          map: {key: value, key2: value2}\n          one: \"Impossible d'enregistrer {{model}}: 1 erreur\"\n          other: \"Impossible d'enregistrer {{model}}: {{count}} erreurs.\"\n        body: \"Veuillez vérifier les champs suivants :\"\n      messages:\n        inclusion: \"n'est pas inclus(e) dans la liste\"\n        exclusion: \"n'est pas disponible\"\n        invalid: \"n'est pas valide\"\n        confirmation: \"ne concorde pas avec la confirmation\"","output":"Extracted text units with names like:\n- fr/activerecord/errors/template/header/list[0] → \"one\"\n- fr/activerecord/errors/template/header/list[1] → \"two\"\n- fr/activerecord/errors/template/header/list[2] → \"three\"\n- fr/activerecord/errors/template/header/map/key → \"value\"\n- fr/activerecord/errors/template/header/one → \"Impossible d'enregistrer {{model}}: 1 erreur\"\n- fr/activerecord/errors/messages/exclusion → \"n'est pas disponible\""},{"title":"Default inline code patterns","description":"The default codeFinderRules patterns detect printf-style format specifiers, escape sequences, and numbered placeholders as inline codes. The patterns match: %d, %2$s, %+05.2f (printf format specifiers), \\n, \\r\\n, \\t (escape sequences), and {0}, {1} (numbered placeholders).","input":"Default rules:\n  ((%(([-0+#]?)[-0+#]?)((\\d\\$)?)((([\\d\\*]*)(\\.([\\d\\*])*)?))[dioxXucsfeEgGpn])\n  |((\\\\r\\\\n)|\\\\a|\\\\b|\\\\f|\\\\n|\\\\r|\\\\t|\\\\v)\n  |(\\{\\d.*?\\})","output":"Matches converted to inline codes: %d, %2$s, %+05.2f, \\n, \\r\\n, \\t, {0}, {1}"}],"filterId":"okf_yaml","wikiUrl":"https://okapiframework.org/wiki/index.php/yaml_filter"}},"aliases":{"okf_baseplaintext":"okf_plaintext","okf_basetable":"okf_table","okf_commaseparatedvalues":"okf_table","okf_fixedwidthcolumns":"okf_table","okf_paraplaintext":"okf_plaintext","okf_tabseparatedvalues":"okf_table"}}